---
title: "Développement d’un modèle joint de distribution des espèces pour la réalisation d’une carte de biodiversité à Madagascar"
author: "Jeanne Clément"
date: "Rapport de stage, Février à Août 2019"
output:
  pdf_document :
    latex_engine : xelatex
    fig_caption : yes
    pandoc_args: ["--number-sections"]
header-includes: 
  - \usepackage{upgreek}
  - \usepackage{easybmat}
  - \usepackage{float}
  - \usepackage{fancyhdr}
  - \usepackage{hyperref}
  - \usepackage[frenchb]{babel}
  - \usepackage{amsmath,amssymb,amsthm}
  - \usepackage{graphicx}
  - \usepackage[labelfont=bf,textfont=sl,tableposition=top,small]{caption}
  - \usepackage{enumitem}
  - \usepackage{dsfont}
  - \usepackage{bbm}
  - \usepackage{answers}
  - \usepackage{xassoccnt}

bibliography: Biblio_master.bib
geometry: left=1.4cm,right=1.4cm,top=1.5cm,bottom=0.5cm
fontsize : 10pt
---
\renewcommand\UrlFont{\color{blue}\rmfamily\itshape}
\newtheorem{prop}{Proposition}
\RemoveFromReset{prop}{section}
\AddToReset{prop}{subsubsection}
\renewcommand{\theprop}{\thesubsubsection .\arabic{prop}}
\theoremstyle{definition}
\newtheorem{defn}{Définition}
\renewcommand{\thedefn}{\thesubsubsection .\arabic{dfn} }
\newtheorem{dem}{Preuve}
\RemoveFromReset{dem}{section}
\AddToReset{dem}{subsubsection}
\renewcommand{\thedem}{\thesubsubsection.\arabic{dem}}
\newtheorem{thm}{Théorème}
\renewcommand{\thethm}{\thesubsubsection.\arabic{thm}}
\renewcommand{\contentsname}{Sommaire}
\renewcommand{\listtablename}{Liste des tableaux}
\renewcommand{\listfigurename}{Liste des figures}
\renewcommand{\baselinestretch}{1.5}
\fancypagestyle{simple}{\rhead{\thepage} \chead{} \lhead{} \cfoot{}}
\renewcommand{\headrulewidth}{0pt}

\thispagestyle{empty}
\begin{center}

Enseignant référent : Benoite De Saporta  

Encadrant : Ghislain Vieilledent  

\vspace{0.5cm}

```{r illustration, echo=FALSE, include=T, out.width='90%'}
knitr::include_graphics('Illustrations/foret.jpg')
```

\vspace{0.5cm}

Master Maths-Biostatistique  

Université Montpellier 2  

UMR AMAP - Montpellier  

\vspace{1cm}

\includegraphics[height=1.7cm, width=1.7cm]{Illustrations/logo_UM.jpg}
\includegraphics[height=2cm, width=2cm]{Illustrations/logo-AMAP.png}
\includegraphics[height=1.3cm]{Illustrations/titre-long.png}
\includegraphics[height=3.1cm, width=3.1cm]{Illustrations/Logo-Cirad.png}
\end{center}

```{r options, echo=FALSE,include=F}
library(Rcpp)
library(RcppArmadillo)
library(RcppGSL)
library(knitr)
library(kableExtra)
knit_engines$get("Rcpp")
knit_engines$set("Rcpp")
opts_chunk$set(echo=TRUE, cache=FALSE,
               #results="hide", 
               warning=FALSE,
               message=FALSE, highlight=TRUE,
               fig.show="hide", size="small",
               fig.align="center",
               tidy=FALSE)
options(knitr.kable.NA="-")
```

\newpage
\thispagestyle{empty}
\section*{Remerciements}

J'aimerai adresser mes plus sincères remerciements à G. Vieilledent qui m'a encadrée et conseillée durant ce stage riche en découvertes puisque le language C++, la construction de packages R ainsi que les modèles joints de distribution des espèces m'étaient inconnus. Il m'a beaucoup appris et encouragée à trouver des solutions par moi même. Je remercie également les chercheurs et autres stagiaires de l'UMR AMAP pour leur accueil chaleureux et leur bonne humeur communicative qui font du laboratoire un cadre de travail idéal et tout particulièrement G. Le Moguedec qui fut une référence précieuse en statistiques ainsi que l'instigateur de pique-niques au lac du Crès qui nous ont bien aidé à supporter la canicule. 

\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables

\newpage
\setcounter{page}{1} 
\thispagestyle{simple}
\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

J'ai effectué mon stage au sein de l'UMR AMAP (botAnique et Modélisation de l'Architecture des Plantes et des végétations), qui se trouve à Montpellier. Il s'agit d'une unité interdisciplinaire hébergée par le Cirad ou « Centre de Coopération Internationale en Recherche Agronomique pour le Développement», qui mène des recherches sur les plantes et les végétations, dans le but de prévoir la réponse des écosystèmes aux forçages environnementaux.  

Ce stage s'inscrit dans le cadre du projet BioSceneMada qui vise à fournir des scénarios d'évolution de la biodiversité sous l’effet conjoint du changement climatique et de la déforestation à Madagascar. Pour ce faire, plusieurs jeux de données sur la biodiversité ont été collectés et regroupés pour différents groupes taxonomiques (mammifères, oiseaux, reptiles, amphibiens, arbres, plantes herbacées, invertébrés), parmi lesquels j'ai utilisé les inventaires forestiers répertoriant l'absence ou la présence d'espèces d'arbres sur différents sites de l'île ainsi que des variables bioclimatques afin d'ajuster un modèle joint de distribution des espèces (JSDM) permettant d’estimer la niche des espèces, de prédire leurs distributions et ainsi d'estimer la biodiversité sur l'île tout en prenant en compte les intéractions entre espèces (@Warton2015). 

On pourrait ajuster un modèle de distribution pour chaque espèce plutôt qu'un JSDM en utilisant le package R hSDM décrit dans l'article @Vieilledent2014 qui permet de modéliser la distribution et l’abondance des espèces indépendamment les une des autres via des modèles de mélange pouvant prendre en compte l’autocorrelation spatiale des données (via un processus CAR). Ce package s’appuie sur des modèles hiérarchiques Bayésiens intégrant des variables latentes et des eﬀets aléatoires. Cependant cette approche est limitée car elle néglige les intéractions biotiques entre les espèces et ne considère qu'un filtrage environnemental pour estimer les probabilités de présence d'une espèce contrairement aux modèles joints de distribution qui prennent en compte l'information apportée par les autres espèces.  

En effet les modèles joints de distributions sont des modèles de communauté qui permettent d'emprunter de l'information aux autres espèces pour estimer les paramètres correspondants à une espèce pour laquelle on dispose de peu d'observations c'est à dire dont la présence est rarement observée. 
De plus l'intégration de variables non mesurées ou non mesurables dans ce type de modèle va permettre l'estimation d'une matrice de corrélation résiduelle entre les espèces comme on le verra par la suite. 
Ils peuvent être utilisés pour déterminer la biodiversité $\beta$, c’est-à-dire les communautés ou assemblages d’espèces et comment ces assemblages changent spatialement (“species turnover”), selon des gradients environnementaux (d’altitude, de climat, etc.) ainsi que la biodiversité $\alpha$ ou richesse spécifique qui reflète le nombre d'espèces présentes sur un site.   

Or il existe peu de logiciels et de fonctions permettant d'ajuster ces modèles de distribution jointe des espèces, les principaux sont les packages boral, gjam, HMSC et BayesCo dont les performances sont comparées dans l'article @Wilkinson2019. Cependant ces fonctions nécessitent un temps de calcul assez important pour ajuster un JSDM sur des jeux de données bien moins conséquents que celui dont on dispose concernant Madagascar, il n'est donc pas envisageable de les utiliser sur nos données. 

Par conséquent l'un des objectifs du stage était d'implémenter un échantillonneur de Gibbs en C++ permettant d’estimer les paramètres de modèles joints de distribution des espèces (JSDM) comportant des variables latentes le plus efficacement possible. Pour ce faire j'ai utilisé les tirages aléatoires optimisés issue de la librairie GSL et le type de matrice définie par la librairie Armadillo qui permet de manipuler facilement les matrices et d'effectuer des calculs matriciels importants en peu de temps, lors de l'implémentation des fonctions en C++ qui seront intégrées à un package R à l'aide du package Rcpp.  

En effet j'ai construit, avec l'aide de mon encadrant, le package R \url{https://ecology.ghislainv.fr/jSDM/} autour de ces fonctions, ce qui comprend la rédaction des aides et des vignettes ainsi que l'implémentation des tests nécessaires à la publication du package sur le CRAN.  

Par la suite nous avons présenté ce package lors de la conférence useR 2019 qui se déroulait à Toulouse pendant quatre jours, durant lesquels j'ai également suivi des tutoriels qui m'ont permis de me familiariser avec l'utilisation des packages sp, raster et gstat utilisés dans le cadre de l'interpolation spatiale sur l'ensemble de l'île des paramètres estimés sur les placettes d'inventaire.    

L'ensemble des fonctions implémentées ainsi que les données et les codes utilisés sont disponibles sur le répertoire Github \url{https://github.com/JeanneClement/Report}.

\newpage
\pagestyle{headings}


# Définition des modèles joints de distribution des espèces envisagés \quad

Les données dont on dispose pour ajuster ce type de modèle sont les réalisations d'une variable réponse,  
$Y=(y_{ij})^{i=1,\ldots,I}_{j=1,\ldots,J}$ telle que :

$$y_{ij}=\begin{cases}
    0 & \text{ si l'espèce $j$ est absente du site $i$}\\
    1 &  \text{ si l'espèce $j$ est présente sur le site $i$,}
    \end{cases}$$
ainsi que de variables explicatives $X=(X_i)_{i=1,\ldots,I}$ avec $X_i=(X_{i1},\ldots,X_{ip})\in \mathbb{R}^p$ où $p$ est le nombre de variables bioclimatiques considérées pour chaque site.  
On note $\theta_{ij}$, la probabilité de présence de l'espèce $j$ sur le site $i$.

L'article @Warton2015 développe deux approches hiérarchiques  pouvant être utilisées à la spécification d’un modèle joint de distribution des espèces.

## Modèle linéaire mixte généralisé multivarié (GLMM) 

D'une part on pourrait utiliser un modèle linéaire mixte généréralisé multivarié **(GLMM)** de la forme : 
$$g(\theta_{ij}) =\alpha_i + \beta_{j0} + X_i\beta_j + u_{ij},$$
$$y_{ij} \ | \ u_{ij}, \alpha_i \sim \mathcal{B}ernoulli(\theta_{ij}),$$
$$u_i \sim \mathcal{N}_J(0_{\mathbb{R}^J},\Sigma) \ iid,$$
$$\alpha_i \sim \mathcal{N}(0, V_{\alpha}) \ iid \text{ et indépendant de } u_i.$$
où $g : \ ]0,1[ \ \rightarrow \ ]-\infty, +\infty[$ est une fonction de lien, $\beta_j=(\beta_{j1},\ldots,\beta_{jp})'$ et $\beta_{j0}$ sont les coefficients de régression correspondants aux variables bioclimatiques et l'intercept pour l'espèce $j$ qui est supposé être un effet fixe, $\alpha_i$ représente l'effet aléatoire du site $i$, et $u_i=(u_{i1},\ldots,u_{iJ})$ est un effet aléatoire multivarié corrélé dont la matrice de variance covariance $\Sigma$ controle la corrélation entre les espèces et est supposée être complètement non structurée.    
Cette dernière partie du modèle est problématique lorsque le nombre d'espèces $J$ est important car le nombre de paramètres dans $\Sigma$ augmente quadratiquement avec $J$.

## Modèle à variable latente (LVM)

D'autre part en posant $u_{ij} = W_i\lambda_j$, avec $W_i=(W_{i1},\ldots,W_{iq})$ les $q$ variables latentes (ou "variables latentes") considérés et $\lambda_j=(\lambda_{j1},\ldots, \lambda_{jq})'$ les coefficients associés, on obtient le modèle à variables latentes **(LVM)** suivant : 
$$g(\theta_{ij}) =\alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$$
$$y_{ij} \ | \ W_i, \alpha_i \sim \mathcal{B}ernoulli(\theta_{ij}),$$
$$W_i \sim \mathcal{N}(0,I_q) \ iid $$
$$\alpha_i \sim \mathcal{N}(0,V_{\alpha}) \ iid \text{ et indépendant de } W_i$$ 

Ce qui revient à un cas particulier de GLMM auquel on impose la contrainte $\Sigma = \Lambda\Lambda'$ avec 
$$\Lambda := \begin{pmatrix}
\lambda_{11} & \ldots & \lambda_{1q} \\
\vdots & \vdots & \vdots \\
\lambda_{J1} & \ldots & \lambda_{Jq}
\end{pmatrix}$$

On préferera ce dernier modèle, en effet il comporte potentiellement beaucoup moins de paramètres que le GLMM précédent car $\Lambda$ a autant de colonne qu’il y a de variables latentes ($q$) tandis que $\Sigma$ présente autant de colonnes de paramètres qu’il y a d’espèces ($J$).  

Dans la suite on fixera $q=2$, en effet comme @Warton2015 on considérera des modèles à deux variables latentes par analogie avec une analyse par composante principale (ACP) sur les résidus pour lesquels on utilise souvent les deux ou trois premiers axes car l'intégration de variables latentes aux modèles s'apparente à une forme d'ordination.

On peut choisir de modéliser l'abondance absolue plutôt que l'abondance relative en supprimant les effets sites aléatoires  $\alpha_i$ du modèle. 

# Méthodes d’inférence bayesienne selon la fonction de lien choisie 

## Principe d’un échantillonneur de Gibbs

Dans le cadre bayésien, l’algorithme de Gibbs permet d’obtenir une réalisation du paramètre $\theta=(\theta_),\ldots,\theta_m)$ suivant la loi *a posteriori* $\uppi(\theta \ | \ x)$ dès que l’on est capable d’exprimer les lois conditionnelles : $\uppi(\theta_i \ | \ \theta_1,\dots,\theta_{i-1},\theta_{i+1},\ldots,\theta_m, x)$ pour $i =1,\ldots,m$.  

\vspace{0.2cm}

L’**échantillonnage de Gibbs** consiste à : 
\begin{itemize}
\item \textbf{Initialisation} : choix arbitraire de $\theta^{(0)}= (\theta_1^{(0)},\dots,\theta_m^{(0)})$.
\vspace{0.2cm}
\item \textbf{Itération $t$} : Générer $\theta^{(t)}$ de la manière suivante :
\vspace{0.2cm}
  \begin{itemize}
  \item[$\bullet$] $\theta_1^{(t)} \sim \uppi\left(\theta_1 \ | \theta_2^{(t-1)},\dots, \theta_m^{(t-1)}, x \right)$
\vspace{0.1cm}
  \item[$\bullet$] $\theta_2^{(t)} \sim \uppi\left((\theta_2 \ | \ (\theta_1^{(t)}, \theta_3^{(t-1)},\ldots,\theta_m^{(t-1)},x\right)$
  \item[$\bullet$] $\theta_m^{(t)} \sim \uppi\left(\theta_m \ | \ \theta_1^{(t)}, \ldots, \theta_{m-1}^{(t)},x\right)$
\end{itemize}
\end{itemize}

Les itérations successives de cet algorithme génèrent les états d’une chaîne de
Markov $\{\theta^{(t)}, t > 0\}$ à valeurs dans $\mathbb{R}^{m}$, on montre que cette chaîne admet une mesure invariante qui est la *loi a posteriori*.  
Pour un nombre d’itérations suffisamment grand, le vecteur $\theta$ obtenu peut donc être considéré comme étant une réalisation de la loi *a posteriori* jointe $\uppi(\theta \ | \ x)$. 
\vspace{0.2cm} 

Par conséquent l'implémentation d'un échantillonneur de Gibbs nécessite la connaissance des distributions *a posteriori* de chacun des paramètres conditionnellement aux autres paramètres du modèle, qui se déduisent des formules de priors conjugués dans le cas du modèle probit mais ne sont pas explicitement exprimables dans le cas où on utilise une fonction de lien logit.

## Modèle probit : échantillonneur de Gibbs et priors conjugués 

D’une part, on utilise un fonction de lien $\mathrm{probit} : p \rightarrow \Phi^{-1}(p)$ où $\Phi$ correspond à la fonction de répartition d’une loi normale centrée réduite.  

### Définition du modèle probit

D’après l’article @Albert1993, une modélisation possible est de supposer l’existence d’une variable latente sous-jacente liée à notre variable binaire observée en utilisant la proposition suivante :

\begin{prop}[Modèle probit par l'intermédiaire d'une variable latente]  \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad  \qquad \qquad \qquad  \qquad \qquad \qquad \qquad   

Si $Z_{ij} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j + \epsilon_{ij}, \ \forall i,j \text{ avec }  \epsilon_{ij} \sim \mathcal{N}(0,1) \ iid $ et tel que :
$$y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$$
Alors on a $y_{ij} \ |\ Z_{ij} \sim \mathcal{B}ernoulli(\theta_{ij})$ avec
$\mathrm{probit(\theta_{ij})} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j$.
\end{prop}
\begin{dem}   
$$\begin{aligned}
\mathbb{P}(y_{ij}=1) & = \mathbb{P}(Z_{ij} > 0)\\
& = \mathbb{P}(\alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j + \epsilon_{ij} > 0)\\
& = \mathbb{P}(\epsilon_{ij} > - (\alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \ ) \\
& = \mathbb{P}(\epsilon_{ij} \leq \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
& = \Phi( \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
\end{aligned}$$
De la même façon on a :   
$$\begin{aligned}
\mathbb{P}(y_{ij}=0) & = \mathbb{P}(Z_{ij} \leq 0)\\
& = 1 - \Phi( \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
\end{aligned}$$
\end{dem}
On définit le modèle probit à l’aide d’une variable latente afin d’être en mesure d’utiliser les propriétés des priors conjugués pour échantillonner les paramètres du modèle selon leurs distributions conditionnelles *a posteriori*. 

### Priors utilisés 

Afin d’utiliser une méthode d’inférence bayesienne on détermine une distribution *a priori* pour chacun des paramètres du modèle :
$$\begin{array}{lll}
V_{\alpha} & \sim & \mathcal {IG}(\text{shape}=0.5, \text{rate}=0.005) \text{ avec } \mathrm{rate}=\frac{1}{\mathrm{scale}}, \\
\beta_{jk} & \sim & \mathcal{N}(0,10^6)  \text{ pour } j=1,\ldots,J \text{ et } k=1,\ldots,p, \\
\lambda_{jl} & \sim & \begin{cases}
\mathcal{N}(0,10) & \text{si } l < j \\
\mathcal{N}(0,10) \text{ tronquée à gauche par } 0 & \text{si } l=j \\
P \text{ tel que } \mathbb{P}(\lambda_{jl} = 0)=1  & \text{si } l>j
\end{cases} \\
\quad & \quad & \text{ pour } j=1,\ldots,J \text{ et } l=1,\ldots,q.
\end{array}$$
En effet pour assurer l’identifiabilité du modèle les valeurs de $\Lambda$ sont contraintes à des valeurs strictements positives sur la diagonale et nulles au dessus de celle-ci, $\Lambda$ est ainsi supposée être triangulaire inférieure d’après l’article @Warton2015. 

La fonction *boral()* du package du même nom présenté dans l'article @Hui2016 et permettant d'ajuster différents JSDM utilise ces distributions *a priori* pour le modèle qui nous intéresse. 
Cependant la fonction *jSDM_probit_block()* du package jSDM que j'ai implémentée utilise une distribution *a priori* jointe pour les effets espèces fixes de la manière qui suit.

### Propositions sur les priors conjugués  

**Effets espèces fixes**:  

On se ramène à un modèle de la forme $Z^* = X\beta + \epsilon$, en posant $Z^*_{ij} = Z_{ij}  - \alpha_i = \beta_{j0} + X_i\beta_j+ W_i\lambda_j+\epsilon_{ij}$, afin d'estimer simultanément les $\beta_j$ et $\lambda_j$ pour chacune des espèces $j$,   ce qui revient en écriture matricielle à : 
$$\begin{aligned} 
Z^*_{j} = &\begin{pmatrix} 
Z^*_{1j} \\
\vdots \\
Z^*_{Ij}
\end{pmatrix} =  \underbrace{
\begin{pmatrix}
 1 & X_{11} & \ldots & X_{1p} & W_{11} & \ldots & W_{1q}\\
 \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 1 & X_{I1} & \ldots & X_{Ip} & W_{I1} & \ldots & W_{Iq}\\
\end{pmatrix}}_{D}
\underbrace{
\begin{pmatrix}
\beta_{j0} \\
\beta_{j1} \\
\small{\vdots} \\
\beta_{jp} \\
\lambda_{j1} \\
\small{\vdots} \\
\lambda_{jq} 
\end{pmatrix}}_{P_j}
+ \begin{pmatrix} 
\epsilon_{1j} \\
\vdots \\
\epsilon_{Ij}
\end{pmatrix} \\
& =  DP_j + \epsilon_j \quad \text{ avec } \epsilon_j \sim \mathcal{N}_I(0_{\mathbb{R}^I},I_I).
\end{aligned}$$
On suppose que $P_j \sim \mathcal{N}_{p+q+1}(m,V)$ avec $m=0_{\mathbb{R}^{p+q+1}}$ et $V=diag(\underbrace{10^6,\ldots,10^6}_{\times p+1},\underbrace{10,\ldots,10}_{\times q})$, par exemple.  
Bien que cette distribution *a priori* ne prenne pas en compte les contraintes sur $\Lambda$, elle permet l'échantillonnage selon une loi normale multivariée des effets espèce fixes. On imposera les contraintes aux $\lambda_{jl}$ concernés après les avoir simulés. 

On applique la proposition suivante : 

\begin{prop}
$$\begin{cases} 
Y \ | \ \beta \sim \mathcal{N}_n ( X\beta, I_n) \\
\beta  \sim \mathcal{N}_p (m,V)
\end{cases}
\Rightarrow \begin{cases}
\beta|Y \sim \mathcal{N}_p (m^*,V^*) \text{ avec }  \\
m^* = (V^{-1} + X'X)^{-1}(V^{-1}m + X'Y)\\
V^*=(V^{-1} + X'X)^{-1} 
\end{cases}$$.
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\beta \ | \ Y) & \propto  p(Y \ | \ \beta) \ p(\beta) \\
& \propto  \frac{1}{(2\pi)^{\frac{n}{2}}}\exp\left(-\frac{1}{2}(Y-X\beta)'(Y-X\beta)\right)\frac{1}{(2\pi)^{\frac{p}{2}}|V|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}(\beta-m)'V^{-1}(\beta-m)\right) \\
& \propto \exp\left(-\frac{1}{2}\left((\beta-m)'V^{-1}(\beta-m) + (Y-X\beta)'(Y-X\beta)\right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'V^{-1}\beta + m'V^{-1}m - m'V^{-1}\beta -\beta'V^{-1}m + Y'Y + \beta'X'X\beta - Y'X\beta - \beta'X'Y\right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (Y'X + m'V^{-1})\beta + m'V^{-1}m + Y'Y \right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (X'Y + V^{-1}m)'\beta + m'V^{-1}m + Y'Y \right)\right) \\
& \propto \exp(-\frac{1}{2}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)'(V^{-1}+X'X)\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\\
& \quad -(V^{-1}m + X'Y)'(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y) +m'V^{-1}m + Y'Y)\\
& \propto \exp\left(-\frac{1}{2}\left(\beta - \underbrace{(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)}_{m^*}\right)'\underbrace{(V^{-1}+X'X)}_{{V^*}^{-1}}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\right)
\end{aligned}$$
\end{dem}
On obtient : 
$$\begin{cases} 
Z^*_j \ | \ P_j \sim \mathcal{N}_{I} ( DP_j, I_{I}) \\
P_j \sim \mathcal{N}_{p+q+1}(m,V)
\end{cases}
\Rightarrow \begin{cases}
P_j \ | \ Z^*_j  \sim \mathcal{N}_{p+q+1} (m^*,V^*) \text{ avec }  \\
m^* = (V^{-1} + D'D)^{-1}(V^{-1}m + D'Z^*_j)\\
V^*=(V^{-1} + D'D)^{-1} 
\end{cases}$$.

**Variables latentes (prédicteurs non mesurés) : **
De la même façon, on pose : $Z^\star_{ij} = Z_{ij} - \alpha_i - \beta_{j0} - X_i\beta_j = W_i\lambda_j + \epsilon_{ij}$, afin d’estimer $W_i$ pour chaque site $i$.  
En appliquant la proposition précédente, on obtient :
$$\begin{cases} 
Z^*_i := (Z^*_{i1},\ldots,Z^*_{iJ})' \ | \ W_i \sim \mathcal{N}_{J} ( \Lambda W_i', I_{J}) \\
W_i' \sim \mathcal{N}_{q}(0_{\mathbb{R}^{q}},I_q)
\end{cases}
\Rightarrow \begin{cases}
W_i' \ | \ Z^*_i \sim \mathcal{N}_{q} (m^*,V^*) \text{ avec }  \\
m^* = (I_q + \Lambda'\Lambda)^{-1}(\Lambda'Z^*_i)\\
V^* = (I_q + \Lambda'\Lambda)^{-1} 
\end{cases}$$.
**Effets sites aléatoires et variance associée : **   
En ce qui concerne les effets sites aléatoires  $(\alpha_i)_{i=1,\dots,I}$, on pose $Z^*_{ij} = Z_{ij} - D_iP_j = \alpha_i + \epsilon_{ij}$, avec $D_i =(1,X_{i1},\ldots,X_{ip},W_{i1},\ldots,W_{iq})$. \smallskip   
On a ainsi $Z^*_{ij} \ | \ \alpha_i \ \sim \mathcal{N}(\alpha_i,1)$ *iid* pour $j=1,\ldots,J$, puis on applique la proposition suivante : 
\begin{prop}
$$\begin{cases} 
x_i \ | \ \theta \sim \mathcal{N}(\theta, \ \sigma^2) \ iid \text{ pour } i=1,\ldots,n\\
\theta \sim \mathcal{N}(\mu_0,{\tau_0}^2) \\
\sigma^2 \text{ connu}
\end{cases}
\Rightarrow
\begin{cases} 
\theta | \ x_1, \ldots,x_n \sim \mathcal{N}(\mu_1,{\tau_1}^2) \text{ avec } \\
\mu_1 = \dfrac{{\tau_0}^{-2}\mu_0 + \sigma^{-2}\sum_{i=1}^nx_i}{{\tau_0}^{-2}+n\sigma^{-2}} \\
{\tau_1}^{-2} = {\tau_0}^{-2}+n\sigma^{-2}
\end{cases}$$. 
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\theta \ | \ x_1,\ldots,x_n) & \propto p(\theta) p(x_1,\ldots,x_n \ | \ \theta) \\
& \propto  \frac{1}{(2\pi{\tau_0}^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2\right) \prod\limits_{i=1}^n\frac{1}{(2\pi\sigma^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x_i-\theta)^2\right) \\
& \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2-\frac{1}{2\sigma^2}\sum\limits_{i=1}^n(x_i-\theta)^2\right) \\
& \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta^2-2\mu_0\theta)-\frac{1}{2\sigma^2}\sum\limits_{i=1}^n(\theta^2-2\theta x_i)\right)\\
& \propto \exp\left(-\frac{1}{2}\left(\theta^2 ({\tau_0}^{-2}+n\sigma^{-2})-2\mu_0\theta{\tau_0}^{-2}-2\theta\sigma^{-2}\sum\limits_{i=1}^n x_i\right)\right)\\
& \propto \exp\left(-\frac{1}{2({\tau_0}^{-2}+n\sigma^{-2})^{-1}}\left(\theta -\frac{\mu_0{\tau_0}^{-2}+ \sigma^{-2}\sum\limits_{i=1}^n x_i}{{\tau_0}^{-2}+n\sigma^{-2}}\right)^2\right)\\
\end{aligned}$$
\end{dem}
On obtient ainsi : 
$$\begin{cases} 
Z^*_{ij} \ | \ \alpha_i \sim \mathcal{N}(\alpha_i, \ 1) \text{, iid } \forall j=1,\ldots,J\\
\alpha_i \sim \mathcal{N}(0,V_{\alpha}) \\
\end{cases}
\Rightarrow
\begin{cases} 
\alpha_i | \ Z^*_{i1}, \ldots, Z^*_{iJ} \sim \mathcal{N}(\mu_1,{\tau_1}^2) \text{ avec } \\
\mu_1 = \dfrac{ \sum_{j=1}^J Z^*_{ij}}{V_{\alpha}^{-1}+ J} \text{ et } {\tau_1}^{-2} = V_{\alpha}^{-1}+ J.
\end{cases}$$
Finalement pour estimer $V_{\alpha}$, la variance des effets sites aléatoires $(\alpha_i)_{i=1,\dots,I}$, on utilise la proposition suivante :
\begin{prop}
Si $$\begin{cases} 
x \ | \ \sigma^2 \sim \mathcal{N}_n (\theta, \ \sigma^2I_n) \\
\sigma^2   \sim \mathcal{IG} (a,b) \\
\theta \text{ connu}
\end{cases} \Rightarrow 
\begin{cases}
\sigma^2|x \sim \mathcal{IG}(a',b') \text{ avec } \\
a' = a + \frac{n}{2} \text { et } b' = \frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2 + b. 
\end{cases}$$
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\sigma^2 \ | \ x) & \propto  p(x \ | \ \sigma^2) \ p(\sigma^2) \\
& \propto  \frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x-\theta)'(x-\theta)\right)\frac{b^a}{\Gamma(a)}{(\sigma^2)}^{-(a+1)}\exp\left(-\frac{b}{\sigma^2}\right) \\
& \propto {(\sigma^2)}^{-\left(\frac{n}{2}+a+1\right)}\exp\left(-\frac{1}{\sigma^2}\left(b+\frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2\right)\right)
\end{aligned}$$
\end{dem}
On a donc : $$\begin{cases} 
(\alpha_1,\ldots,\alpha_I)' \ | \ V_{\alpha} \sim \mathcal{N}_n (0_{\mathbb{R}^I}, V_\alpha I_n) \\
V_\alpha \sim \mathcal{IG} (a,b) \\
\end{cases} \Rightarrow 
\begin{cases}
V_\alpha \ | \ \alpha_1,\ldots,\alpha_I \sim \mathcal{IG}(a',b') \text{ avec } \\
a' = a + \frac{I}{2} \text{ et } b' = b + \frac{1}{2}\sum\limits_{i=1}^I \alpha_i^2. 
\end{cases}$$

\newpage

### Echantillonneur de Gibbs et priors conjugués

L’algorithme utilisé pour estimer les paramètres du modèle logit est donc le suivant :
\begin{itemize}
\item Définir les constantes $N_{Gibbs}$, $N_{burn}$, $N_{thin}$ telles que $N_{Gibbs}$ correspond au nombre d’itérations effectuées par l’échantillonneur de Gibbs,  $N_{burn}$ au nombre d’itérations nécessaires pour le burn-in ou temps de chauffe et $N_{samp} = \dfrac{N_{Gibbs}-N_{burn}}{N_{thin}}$ au nombre de valeurs estimées retenues pour chaque paramètre. En effet on enregistre les paramètres estimés à certaines itérations, afin d’obtenir un échantillon de $N_{samp}$ valeurs distribuées selon la distribution $a \ posteriori$ pour chacun des paramètres.
\vspace{0.2cm}
\item Initialiser tous les paramètres à $0$ par exemple, excepté les valeurs diagonales de $\Lambda$ initialisées à $1$ et $V_{\alpha}^{(0)}=1$.
\vspace{0.2cm}
\item Gibbs sampler : à chaque itération $t$ pour $t=1,\ldots,N_{Gibbs}$ on répète chacune de ces étapes :
  \begin{itemize}
  \item[$\bullet$] Génerer la \textbf{variable latente} $Z^{(t)}=\left(Z_{ij}^{(t)}\right)_{i=1,\ldots,I}^{j=1,\ldots,J}$ telle que
$$Z_{ij}^{(t)} \sim  \begin{cases} 
\mathcal{N}\left(\alpha_i^{(t−1)} + \beta_{j0}^{(t−1)} + X_i\beta_j{(t−1)} + W_i^{(t−1)}\lambda_j^{(t−1)}, \ 1 \right) \text{ tronquée à droite par } 0 & \text{si } y_{ij } =0 \\ 
\mathcal{N}\left(\alpha_i^{(t−1)} + \beta_{j0}^{(t−1)} + X_i\beta_j{(t−1)} + W_i^{(t−1)}\lambda_j^{(t−1)}, \ 1 \right) \text{ tronquée à gauche par } 0 &        \text{si } y_{ij} =1
\end{cases}$$
, la variable latente est ainsi initialisée à la première itération en la générant selon ces lois normales centrées.
\vspace{0.1cm}
  \item[$\bullet$] Générer les \textbf{effets espèces fixes} $P_j^{(t)}=(\beta_{j0}^{(t)},\beta_{j1}^{(t)} \ldots, \beta_{jp}^{(t)},\lambda_{j1}^{(t)},\ldots, \lambda_{jq}^{(t)})'$ pour $j=1,\ldots,J$ selon : 
$$P_j^{(t)} \ | \ Z^{(t)}, W_1^{(t-1)}, \alpha_1^{(t-1)}, \ldots, W_I^{(t−1)}, \alpha_I^{(t-1)} \sim \mathcal{N}_{p+q+1}(m^\star,V^\star) \text{, avec }$$
$$m^\star = (V^{-1} + {D^{(t)}}'D^{(t)})^{-1}(V^{-1}m + {D^{(t)}}'Z^\star_j) \text{ et } V^\star = \left(V^{-1}+{D^{(t)}}'D^{(t)}\right)^{-1},$$
$$\text{où } Z_j^\star =(Z_{1j}^\star,\ldots,Z_{Ij}^\star)' \text{ tel que } Z^\star_{ij} = Z_{ij}^{(t)}-\alpha_i^{(t-1)}.$$
Afin de contraindre les valeurs diagonales de $\Lambda =\left(\lambda_{jl}\right)_{j=1,\ldots,J}^{l=1,\ldots,q}$ à des valeurs positives et de rendre la
matrice triangulaire inférieure, on modifie les valeurs des $P^{(t)}$ simulées aléatoirement selon les conditions suivantes :
$$P_{jp+1+l}^{(t)} = \lambda_{jl}^{(t)} \leftarrow \begin{cases}
0 & \text{si } l>j \\
\lambda_{jl}^{(t-1)} & \text{si } l=j \text{ et } \lambda_{jl}^{(t)} < 0.
\end{cases}$$ 
On pose $P^{(t)}=\left( P_1^{(t)} | \ldots | P_J^{(t)} \right)$.  
\vspace{0.1cm}
\item[$\bullet$] Générer les \textbf{variables latentes} (ou prédicteurs non mesurés) $W_i^{(t)}$ pour $i=1,\ldots,I$ selon : $$W_i^{(t)} \ | \ Z^{(t)}, P^{(t)},  \alpha_i^{(t-1)} \sim \mathcal{N}_{q} \left((I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}({\Lambda^{(t)}}'Z_i^{\star \star}),(I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}\right),$$
$$\text{où } Z_i^{\star \star} =(Z_{i1}^{\star \star},\ldots,Z_{iJ}^{\star \star}) \text{ tel que } Z_{ij}^{\star \star } = Z_{ij}^{(t)}-\alpha_i^{(t-1)} − \beta_{j0}^{(t)} - X_i\beta_j^{(t)}.$$ On pose $D_i^{(t)} = \left(1,X_{i1},\ldots,X_{ip},W_{i1}^{(t)}, \ldots, W_{iq}^{(t)} \right)$.
  \item[$\bullet$] Générer les \textbf{effets sites aléatoires} $\alpha_i^{(t)}$ pour $i=1,\ldots,I$ selon :
$$ \alpha_i | \ Z^{(t)}, P^{(t)},W_i^{(t)} \sim \mathcal{N}\left(\dfrac{ \sum_{j=1}^J Z_{ij}^{(t)} - D_i^{(t)}P_j^{(t)}}{{V_{\alpha}^{(t-1)}}^{-1} + J} , \left( \frac{1}{V_{\alpha}^{(t-1)}}+ J \right)^{-1}  \right)$$
  \item[$\bullet$] Générer la \textbf{variance des effets sites aléatoires} $V_\alpha^{(t)}$ selon : $$V_\alpha^{(t)} \ | \ \alpha_1^{(t)},\ldots,\alpha_I^{(t)} \sim \mathcal{IG}\left( \text{shape}=0.5 + \frac{I}{2}, \text{rate}=0.005 + \frac{1}{2}\sum\limits_{i=1}^I \left(\alpha_i^{(t)}\right)^2\right)$$
  \end{itemize}
\end{itemize}
\newpage 

## Modèle logit : échantillonneur de Gibbs et algorithme de Metropolis adaptatif 

D'autre part on considère une fonction de lien $\mathrm{logit}: p \rightarrow\ln\left(\frac{p}{1-p}\right)=\mathrm{F}^{-1}(p)$, avec $\mathrm{F}:x\rightarrow \frac{1}{1+e^{-x}}$ la fonction de répartition appelée sigmoïde d’une loi logistique standard. 
 
### Définition du modèle logit

De la même façon que pour le modèle probit, on peut définir le modèle logit par l’intermediaire d’une variable latente : $Z_{ij}= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j + \epsilon_{ij}$ pour $i=1,\ldots,I$ et $j=1,\ldots,J$, avec $\epsilon_{ij} \sim \mathrm{logistique}(0,1)$ *iid* et telle que : 
$$y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$$ 
Cependant dans ce cas les distributions *a priori* de la variable latente et des paramètres n’étant pas conjuguées, on n’est pas en mesure d’utiliser les propriétés des priors conjugués donc la modélisation à l’aide d’une variable latente ne présente pas d’intérêt.    
Dans ce cas on suppose que $$y_{ij} \ | \theta_{ij} \sim \mathcal{B}(n_i,\theta_{ij})$$, avec
$\mathrm{probit(\theta_{ij})} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j$ et $n_i$ le nombre de visites du site $i$.    
Par conséquent on échantillonnera les paramètres de ce modèle selon une estimation de leurs distributions conditionnelles *a posteriori* à l’aide d’un algorithme de Metropolis adaptatif. 

### Priors utilisés 

On détermine une distribution *a priori* pour chacun des paramètres du modèle :  
$$\begin{array}{lll}
V_{\alpha} & \sim & \mathcal {IG}(\text{shape}=0.5, \text{rate}=0.005) \text{ avec } \mathrm{rate}=\frac{1}{\mathrm{scale}}, \\
\beta_{jk} & \sim & \mathcal{N}(0,10^6)  \text{ pour } j=1,\ldots,J \text{ et } k=1,\ldots,p, \\
\lambda_{jl} & \sim & \begin{cases}
\mathcal{N}(0,10) & \text{si } l < j \\
\mathcal{U}(0,10) &  \text{si } l=j \\
P \text{ tel que } \mathbb{P}(\lambda_{jl} = 0)=1  & \text{si } l>j
\end{cases} \\
\quad &  \quad & \text{ pour } j=1,\ldots,J \text{ et } l=1,\ldots,q.
\end{array}$$

### Principe d'un algorithme de Metropolis adaptatif 

Cet algorithme appartient aux méthode MCMC et permet d’obtenir une réalisation du paramètre $\theta=(\theta_),\ldots,\theta_m)$ selon leurs distributions conditionnelles *a posterirori* $\uppi(\theta_i \ | \ \theta_1,\dots,\theta_{i-1},\theta_{i+1},\ldots,\theta_m, x)$, pour $i =1,\ldots,m$ connues à une constante multiplicative près.  
On le qualifie d'adaptatif car la variance de la densité instrumentale conditionnelle utilisée est adaptée en fonction du nombre d'acceptation lors des dernières itérations. 
\begin{itemize}
\item \textbf{Initialisation} : $\theta^{(0)}= (\theta_1^{(0)},\ldots,\theta_m^{(0)})$ fixés arbitrairement, les nombres d'acceptation $(n^A_{i})_{i=1,\ldots,m}$ sont intialisés à $0$ et les variances $(\sigma^2_i)_{i=1,\ldots,m}$ sont intialisées à $1$.
\item \textbf{Itération t} : pour $i=1,\ldots,m$
  \begin{itemize}
  
  \item[$\bullet$] Générer $\theta_i^\star \sim q(\theta_i^{(t-1)},.)$, avec une densité instrumentale conditionnelle $q(\theta_i^{(t-1)},\theta_i^\star)$ symétrique, on choisira une loi $\mathcal{N}(\theta_i^{(t-1)},{\sigma^2_{i}})$ par exemple.
  
  \item[$\bullet$] Calculer la probabilité d'acceptation : 
  $$\gamma=  min\left(1,\dfrac{\uppi\left(\theta_i^\star \ | \ \theta_1^{(t-1)},\dots,\theta_{i-1}^{(t-1)},\theta_{i+1}^{(t-1)},\ldots,\theta_m^{(t-1)}, x \right)}{\uppi\left(\theta_i^{(t-1)} \ | \ \theta_1^{(t-1)},\dots,\theta_{i-1}^{ (t-1)},\theta_{i+1}^{(t-1)},\ldots,\theta_m^{(t-1)},x\right)}\right)$$.
  
  \item[$\bullet$] Retenir $$\theta_i^{(t)} =  
  \begin{cases} 
  \theta_i^\star & \text{ avec probabilité } \gamma \\
  &\text{ si on est dans ce cas le nombre d'acceptation devient : } n^A_{i} \leftarrow n^A_{i} +1 \\
  \theta_i^{(t-1)} & \text{ avec probabilité } 1-\gamma. \\
  \end{cases}$$
  \end{itemize}
  
\item \textbf{Durant le burn-in}, toutes les $\mathrm{DIV}$ itérations, avec 
$$\mathrm{DIV} =  \begin{cases} 
100 & \text{ si } N_{Gibbs} \geq 1000 \\
\dfrac{N_{Gibbs}}{10}& \text{sinon }  \\
\end{cases}$$
, où $N_{Gibbs}$ est le nombre total d'itérations effectuées.   
On modifie les variances en fonction des nombres d'acceptation de la manière suivante pour $i=1,\ldots,m$ : 
\begin{itemize}
  \item[$\bullet$] On calcule le taux d'acceptation : $r^A_{i} = \dfrac{ n^A_i}{\mathrm{DIV}}$.
  \item[$\bullet$] On adapte les variances selon le taux d'acceptation et une constante fixée $R_{opt}$ : $$\sigma_i \leftarrow \begin{cases}  
\sigma_i\left(2-\dfrac{1-r^A_i}{1-R_{opt}}\right) & \text{ si } r^A_{i} \geq R_{opt} \\ \\
\dfrac{\sigma_i}{2-\dfrac{1-r^A_i}{1-R_{opt}}} & \text{ sinon }
\end{cases}$$  
  \item[$\bullet$] On réinitialise les nombres d'acceptation : $n^A_i \leftarrow 0$.  
  \end{itemize} 
\item Toutes les $\dfrac{N_{Gibbs}}{10}$ itérations, on calcule et affiche les taux d'acceptation moyen $m^A = \dfrac{1}{m}\sum\limits_{i=1,\ldots,m}r^A_i$.
\end{itemize}

### Echantillonneur de Gibbs et algorithme de Metropolis adaptatif

On utilise un algorithme de Metropolis adapatatif pour échantillonner les paramètres du modèle selon leurs distributions conditionnelles *a posteriori* estimées à une constante multiplicative près.
Dans un premier temps on définit la fonction $f$ permettant de calculer la vraisemblance du modèle en fonction des paramètres estimés :  
$$ f : \lambda_j,\beta_{j0},\beta_j,\alpha_i, W_i, X_i, y_{ij},n_i \rightarrow  f(\lambda_j,\beta_{j0},\beta_j,\alpha_i, W_i, X_i, y_{ij},n_i)=\mathrm{L}(\theta_{ij})$$
\begin{itemize}
\item Calcul $\mathrm{logit}(\theta_{ij})= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$.
\item Calcul $\theta_{ij}= \dfrac{1}{1+\exp\left(-\mathrm{logit}(\theta_{ij})\right)}$.
\item Renvoi $\mathrm{L}(\theta_{ij})= p(y_{ij} \ | \ \theta_{ij},n_i)= \dbinom{n_i}{y_{ij}}(\theta_{ij})^{y_{ij}}(1-\theta_{ij})^{n_i-y_{ij}}$.
\end{itemize}
On répète ces étapes pour $i=1,\ldots,I$ et $j=1,\ldots,J$, et on pose $\theta = \left(\theta{ij}\right)_{i=1,\ldots I}^{j= 1,\ldots,J}$.  
On peut ainsi calculer la vraisemblance du modèle : $\mathrm{L}(\theta)= \prod\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\mathrm{L}(\theta_{ij})$.  
D’après la formules de Bayes on a $$\mathrm{p}(\theta \ |  \ Y) \propto \uppi(\theta) \mathrm{L}(\theta).$$
On utilise donc les relations suivantes pour approcher les densités conditionnelles *a posteriori* de chacun des paramètres avec $\uppi(.)$ les densités correspondants à leurs lois *a priori*.
$$\begin{aligned}
& p(\beta_{jk} \ |  \ \beta_{j0},\beta_{j1},\ldots,\beta_{jk-1},\beta_{jk+1},\ldots,\beta_{jp}, \lambda_j,\alpha_1,\ldots,\alpha_I, W_1,\ldots,W_I,Y) \propto \uppi(\beta_{jk})\prod\limits_{1\leq i\leq I}  \mathrm{L}(\theta_{ij})\\
&p(\lambda_{jl} \ |  \ \lambda_{j1},\ldots,\lambda_{jl-1},\lambda_{jl+1},\ldots,\lambda_{jq}, \beta_j,\beta_{j0},\alpha_1,\ldots,\alpha_I, W_1,\ldots,W_I,Y) \propto  \uppi(\lambda_{jl}) \prod\limits_{1\leq i \leq I}\mathrm{L}(\theta_{ij})\\
&p(W_{il} \ |  \ W_{i1},\ldots,W_{il-1},W_{il+1},\ldots,W_{iq},\alpha_i,\beta_{10},\ldots,\beta_{J0},\beta_1,\ldots,\beta_J,\lambda_1,\ldots, \lambda_J,Y) \propto \uppi(W_{il}) \prod\limits_{1\leq j\leq J}\mathrm{L}(\theta_{ij})\\
&p(\alpha_i \ |  \ W_i,\beta_{10},\ldots,\beta_{J0},\beta_1,\ldots,\beta_J,\lambda_1,\ldots, \lambda_j,V_{\alpha},Y) \propto \uppi(\alpha_i \ | \ V_{\alpha}) \prod\limits_{1\leq j\leq J}\mathrm{L}(\theta_{ij})\\
& \text{, pour $i=1,\ldots,I$, $j=1,\ldots,J$, $k=1,\ldots,p$ et $l=1,\ldots,q$. 
}
\end{aligned}$$
\newpage
L’algorithme implémenté en s'inspirant des articles @Rosenthal2009 et @Roberts2001 pour estimer les paramètres du modèle logit est le suivant :
\begin{itemize}
\item Définition des constantes $N_{Gibbs}$, $N_{burn}$, $N_{thin}$ et $R_{opt}$ tels que  $N_{Gibbs}$ correspond au nombre d'itérations effectuées par l'algorithme,  $N_{burn}$ au nombre d'itérations nécessaires pour le burn-in ou temps de chauffe,   
$N_{samp}= \dfrac{N_{Gibbs}-N_{burn}}{N_{thin}}$ correspondant au nombre de valeurs estimées retenues pour chaque paramètre. En effet on enregistre les paramètres estimés à certaines itérations afin d'obtenir $N_{samp}$ valeurs, nous permettant de représenter une distribution $a \ posteriori$ pour chacun des paramètres.  
On fixe $R_{opt}$ le ratio d'acceptation optimal utilisé dans les algorithmes de Metropolis adaptatifs implémentés pour chacun des paramètres du modèle. 
\item Initialiser tous les paramètres à $0$ par exemple, excepté les valeurs diagonales de $\Lambda$ initialisées à $1$ et $V_{\alpha}^{(0)}=1$. Le nombre d'acceptation de chaque paramètre est intialisé à $0$ et les variances de leur densités instrumententales conditionnelles prennent la valeur $1$.
\item Gibbs sampler : à chaque itération $t$ pour $t=1,\ldots,N_{Gibbs}$ on répète chacune de ces étapes :
  \begin{itemize}
\vspace{0.1cm}
\item[$\bullet$] Générer les \textbf{effets sites aléatoires} $\alpha_i^{(t)}$ pour $i=1,\ldots,I$ selon un algorithme de Metropolis adaptatif simulant $\alpha_i^\star \sim \mathcal{N}(\alpha_i^{(t-1)},\sigma_{\alpha_i}^2)$ puis calculant le taux d'acceptation de la manière suivante :  
$$\gamma =min\left(1, \ \dfrac{\uppi\left(\alpha_i^\star \ | \ V_{\alpha}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(\alpha_i^\star, W_i^{(t-1)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}{\uppi\left(\alpha_i^{(t-1)} \ | \ V_{\alpha}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(\alpha_i^{(t-1)}, W_i^{(t-1)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}\right).$$
\item[$\bullet$] Générer la \textbf{variance des effets sites aléatoires} $V_\alpha^{(t)}$ selon : $$V_\alpha^{(t)} \ | \ \alpha_1^{(t)},\ldots,\alpha_I^{(t)} \sim \mathcal{IG}\left( \text{shape}=0.5 + \frac{I}{2}, \text{rate}=0.005 + \frac{1}{2}\sum\limits_{i=1}^I \left(\alpha_i^{(t)}\right)^2\right)$$
\item[$\bullet$] Générer les \textbf{variables latentes} (ou prédicteurs non mesurés) $W_{il}^{(t)}$ pour $i=1,\ldots,I$ et $l=1,\ldots,q$ selon un algorithme de Metropolis adaptatif  simulant $W_{il}^\star \sim \mathcal{N}(W_{il}^{(t-1)}, \sigma_{W_{il}}^2)$ puis calculant le taux d'acceptation de la manière suivante :
$$\gamma = min\left(1,\ \dfrac{\uppi\left(W_{il}^\star\right)\prod\limits_{1\leq j\leq J}f\left(W_{il}^\star, \alpha_i^{(t)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)},X_i,y_{ij},n_i\right)} {\uppi\left(W_{il}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(W_{il}^{(t-1)}, \alpha_i^{(t)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}\right).$$
\item[$\bullet$] Générer les \textbf{effets espèces fixes} $\beta_{jk}^{(t)}$ pour $j=1,\ldots,J$ et $k=0,\ldots,p$ selon un algorithme de Metropolis adaptatif  simulant $\beta_{jk}^\star \sim \mathcal{N}(\beta_{jk}^{(t-1)}, \sigma_{\beta_{jk}}^2)$ puis calculant le taux d'acceptation de la manière suivante :
$$\gamma = min\left(1,\dfrac{\uppi\left(\beta_{jk}^\star\right)\prod\limits_{1\leq i\leq I}f\left(\beta_{j0}^{(t)},\small{\ldots},\beta_{jk-1}^{(t)},\beta_{jk}^\star,\beta_{jk+1}^{(t-1)},\small{\ldots}, \beta_{jp}^{(t-1)},\lambda_j^{(t-1)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)} {\uppi\left(\beta_{jk}^{(t-1)}\right)\prod\limits_{1\leq i\leq I}f\left(\beta_{j0}^{(t)},\small{\ldots},\beta_{jk-1}^{(t)},\beta_{jk}^{(t-1)},\beta_{jk+1}^{(t-1)},\small{\ldots}, \beta_{jp}^{(t-1)},\lambda_j^{(t-1)}, \alpha_1^{(t)},W_1^{(t)}, \small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)}\right).$$
  
\item[$\bullet$] Générer les \textbf{effets espèces fixes liés aux variables latentes} $\lambda_{jl}^{(t)}$ pour $j=1,\ldots,J$ et $l=1,\ldots,q$ selon un algorithme de Metropolis adaptatif pour $l \geq j$, simulant $\lambda_{jl}^\star \sim \mathcal{N}(\lambda_{jl}^{(t-1)},\sigma_{\lambda_{jl}}^2)$ puis calculant le taux d'acceptation de la manière suivante : 
$$\gamma = min\left(1,\dfrac{\uppi\left(\lambda_{jl}^\star\right)\prod\limits_{1\leq i\leq I}f\left(\lambda_{j1}^{(t)},\small{\ldots},\lambda_{jl-1}^{(t)},\lambda_{jl}^\star,\lambda_{jl+1}^{(t-1)},\small{\ldots}, \lambda_{jq}^{(t-1)},\beta_{j0}^{(t)},\beta_j^{(t)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)} {\uppi\left(\lambda_{jl}^{(t-1)}\right)\prod\limits_{1\leq i\leq I}f\left(\lambda_{j1}^{(t)},\small{\ldots},\lambda_{jl-1}^{(t)},\lambda_{jl}^{(t-1)},\lambda_{jl+1}^{(t-1)},\small{\ldots}, \lambda_{jq}^{(t-1)},\beta_{j0}^{(t)},\beta_j^{(t)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)}\right).$$
Dans le cas $l>j$, on pose $\lambda_{jl}^{(t)} = 0$. 
\end{itemize}
\end{itemize}

\newpage  

## Evaluation de la fiabilité de ces méthodes sur des données simulées 

### Simulation des données 

On simule pour chacun des sites $i$ deux variables bioclimatiques selon une loi normale centrée réduite et on note $X_i=(1,X_{i1},X_{i2})$ pour $i=1,\ldots,500$. 
On considérera deux variables latentes.  
On fixe les paramètres suivants afin de simuler des données de présence absence pour les $100$ espèces et $500$ sites considérés selon les deux modèles définis précédemment.  
Les effets espèces fixes générés selon des lois uniformes : 
$$\begin{aligned}
&\beta_{jk} \sim \mathcal{U}(-2,2) \text{ pour } j=1,\ldots,100 \text{ et } k=0,1,2. \\
&\lambda_{jl} \begin{cases} 
\sim  \mathcal{U}(-2,2) & \text{si } l<j, \\
\sim  \mathcal{U}(0,2) & \text{si } l=j, \\
=  0 & \text{si } l>j, 
\end{cases}\\
&\text{ pour } j=1,\ldots,100 \text{ et } l=1,2.
\end{aligned}$$
Les variables latentes $W_{il} \sim \mathcal{N}(0,1) \text{ pour } i=1,\ldots,500 \text{ et } l=1,2$.  
Les effets sites aléatoires générés selon $\alpha_i \sim \mathcal{N}(0,V_{alpha})$ avec $V_{alpha}$ fixé à $0.5$.
Puis on simule les données de présence absence $Y=(y_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ de la manière apropriée pour chacun des modèles envisagés en fonction des paramètres établis : 
\begin{minipage}[l]{0.6\textwidth}
\textbf{Modèle probit :}   
Pour $i=1,\ldots,500$ et $j=1,\ldots,100$ :   
Générer $\epsilon_{ij} \sim \mathcal{N}(0,1) \ iid$.  
Calculer $Z_{ij}= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j + \epsilon_{ij}$ 
Simuler $y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$
\end{minipage}
\begin{minipage}[r]{0.6\textwidth}
\textbf{Modèle logit :}   
Pour $i=1,\ldots,500$ et $j=1,\ldots,100$ :   
Calculer $\mathrm{logit}(\theta_{ij})= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$.  
Calculer $\theta_{ij}= \dfrac{1}{1+\exp\left(-\mathrm{logit}(\theta_{ij})\right)}$.  
Simuler $y_{ij} \sim \mathcal{B}ernoulli(\theta_{ij})$.
\end{minipage}

### Représentation des paramètres estimés 

Les paramètres à estimer sont au nombre de $(p+1)J+qJ-\sum\limits_{j=1}^{q-1}(q-j)+qI+I+1=3\times100+2\times100-1+2\times500+500+1=2 000$, pour chacun d'entre eux les fonctions implémentées retournent un échantillon de $N_{samp}$ valeurs dont on fait la moyenne pour obtenir un estimateur du paramètre.  
On note $\widehat{\beta_{jk}} = \sum\limits_{n=1}^{N_{samp}}\frac{\beta_{jk}^{(n)}}{N_{samp}}$ l'estimateur de $\beta_{jk}$ et on utilise les mêmes notations pour les autres estimateurs.  
On effectue $40 000$ itérations au total dont $35 000$ de burn-in puis $5 000$ durant lesquelles les fonctions implémentées enregistrent les paramètres estimés à partir des données simulées précédemment, toutes les $5$ itérations et renvoient un échantillon de $N_{samp}=1 000$ valeurs pour chacun des paramètres du modèle considéré.   
\textbf{Modèle probit } ajusté avec *Rcpp_jSDM_probit block()* :
\begin{figure}[H]
 \caption[Représentation des $(\alpha_i)_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\alpha_i)_{i=1,\ldots,I}$ estimés en fonction de ceux simulés pour le modèle probit}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/probit_site_effect.png}
\end{figure}
\begin{figure}[H]
 \caption[Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/probit_W.png}
\end{figure}
\begin{figure}[H]
 \caption[Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/probit_sp_effect.png}
\end{figure} 
\begin{figure}[H]
 \caption[Représentation des $(\mathrm{probit}(\theta_{ij}),Z_{ij},\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\mathrm{probit}(\theta_{ij}))_{i=1,\ldots,500}^{j=1,\ldots,100}$, $(Z_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ et $(\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/probit_proba.png}
\end{figure} 
\textbf{Modèle logit } ajusté avec *Rcpp_jSDM_gibbs_logit()* :
\begin{figure}[H]
 \caption[Représentation des $(\alpha_i)_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(\alpha_i)_{i=1,\ldots,I}$ estimés en fonction de ceux simulés pour le modèle logit}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/logit_site_effect.png}
\end{figure}
\begin{figure}[H]
 \caption[Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/logit_W.png}
\end{figure}
\begin{figure}[H]
 \caption[Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle logit}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/logit_sp_effect.png}
\end{figure} 
\begin{figure}[H]
 \caption[Représentation des $(\mathrm{logit}(\theta_{ij}),\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$  estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\mathrm{logit}(\theta_{ij}))_{i=1,\ldots,500}^{j=1,\ldots,100}$ et $(\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/logit_proba.png}
\end{figure} 

### Evaluation du temps de calul et de la pertinence des résultats  

\begin{table}[H]\caption[Temps de calcul nécessaires à l'ajustement des modèles logit et probit ainsi que les NRMSE (Normalized Root Mean Square Error) et les pourcentages de déviance expliquée obtenus]{Temps de calcul nécessaires à l'ajustement des modèles logit et probit ainsi que le pourcentage de déviance expliquée et la racine de la moyenne des carrés des erreurs normalisée (NRMSE) obtenus pour chaque modèle de la manière suivante avec une fonction de lien $g$ probit ou logit :\\
$NRMSE_g=\frac{RMSE_g}{\overline{g(\theta)}}$ avec $\overline{g(\theta)}=\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\frac{g(\theta_{ij})}{IJ}$ et $RMSE=\sqrt{\frac{1}{IJ}\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\left(g(\theta_{ij})-\widehat{g(\theta_{ij})}\right)^2}$.\\ 
Le pourcentage de déviance expliquée est défini par $1-\dfrac{D}{D_0}$ avec $D=-2(l(\widehat{\theta})-l_s)$ la déviance du modèle considéré, où $l_s$ est la log-vraisemblance du modèle saturé comportant autant de paramètres qu'il y a d'observations et dont l'ajustement est supposé parfait par conséquent dans le cas de données binaires, les probabilités ajustées prenant les valeurs $0$ ou $1$ en fonction de celles de $Y$, on a $l_s=0$ car la vraisemblance des données observées sous le modèle saturé est de $1$.\\
De plus la déviance nulle est définie par $D_0=-2(l(\widehat{\theta}_0)-l_s)$ avec $l(\widehat{\theta}_0)$ la log-vraisemblance du modèle nul défini par $g(\theta_{ij})=\mu$, pour lequel le seul paramètre est l'intercept $\mu$.\\
On ajuste le modèle nul avec la fonction jSDM\_binomial() du package jSDM pour le modèle logit et avec Rcpp\_hSDM\_binomial\_probit() pour le modèle probit.\\
Les log-vraisemblance des différents modèles sont calculées avec les paramètres estimés à chaque itération $l(\widehat{\theta})=\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\log(\mathrm{L}(\widehat{\theta_{ij}}))$ et les valeurs utilisées pour le calcul du pourcentage de déviance expliquée correspondent à la moyenne des $N_{samp}$ valeurs retournées par chacune des fonctions implémentées.}
```{r results-probit-logit, echo=F, include=T}
load("data/probit_logit.RData")
library(dplyr)
T_probit<- as.numeric(T_probit,units="mins")
T_logit <- as.numeric(T_logit,units="mins")
results <- data.frame("Temps"=c(T_probit,T_logit), NRMSE=c(NRMSE_probit,NRMSE_logit), D=c(exp_dev_probit,exp_dev_logit)*100)
colnames(results)<- c("Temps de calcul (mins)","NRMSE","Déviance expliquée (%)")
rownames(results)<- c("Modèle probit","Modèle logit")
knitr::kable(results, row.names=T, digits=1,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 
Afin d'ajuster un modèle joint de distribution des espèces à partir des données collectées à Madagascar, on utilisera donc la fonction implémentée pour le modèle probit qui présente un pourcentage de déviance expliquée supérieur, un NRMSE inférieur ainsi qu'un temps de calcul bien inférieur à ceux associés au modèle logit, indiquant que les paramètres estimés sont plus en accord avec les données et proches des valeurs attendues que pour le modèle logit.

\newpage

# Comparaison des résultats obtenus avec les packages boral et jSDM

Dans l'article @Warton2015 l'ajustement de modèles joints de distributions des espèces est réalisé à l'aide de boral qui fonctionne avec JAGS (Just Another Gibbs Sampler) un programme de simulation à partir de modèles hiérarchiques bayésiens utilisant des méthodes MCMC implémentées en C++. Ce package et celui que j'ai implémenté (jSDM) permettent d'ajuster le modèle probit défini précédemment, on pourra donc comparer les résultats obtenus par chacun d'eux sur différents jeux de données. 

## Description des jeux de données utilisés 

Afin de comparer ces packages on utilise un jeu de donnée simulé de la même manière que précédemment selon le modèle probit ainsi que quatre jeux de données réels issus de l'article @Wilkinson2019 qui compare l'ajustement de différents modèle joints de distribution des espèces sur ces données et en particulier ceux implémentés par les packages gjam, HMSC et boral.
\begin{table}[H]\caption[Dimensions des jeux de données utilisés et nombre de paramètres à estimer]{Dimensions des jeux de données utilisés et nombre de paramètres à estimer}
```{r data,echo=F,include=T}
library(knitr)
result <- data.frame(matrix(NA,4,5),row.names=c("Nombre d'espèces", "Nombre de sites","Nombre de covariables","Nombre de paramètres à estimer"))
colnames(result) <- c("Simulation","Moustiques","Eucalyptus","Grenouilles","Champignons")
result[1,]<- c(100,16,12,9,11)
result[2,] <- c(300 ,167,458,104,800)
result[3,] <- c(2,13 ,7 ,3,12 )
result[4,] <- c((2+1)*100+2*100+2*300+300, (13+1)*16+2*16+2*167+167, (7+1)*12+2*12+3*458, (3+1)*9+2*9+3*104, (12+1)*11+2*11+3*800)
kable(result, row.names=T, digits=0,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 

## Comparaison de la pertinence des résultas obtenus et des temps de calcul nécessaires avec chacun des packages 

On ajuste le modèle joint de distribution des espèces défini précèdemment sur des données simulées selon le modèle probit ainsi que sur quatres jeux de données réels à l'aide du package jSDM d'une part et boral d'autre part. Puis puis on compare les résultats obtenus après $35000$ itérations dont $30000$ de burn-in ainsi que les temps de calculs nécessaires. 
\begin{table}[H]\caption[Temps de calcul nécessaire à l'ajustement du modèle pour chacun des jeux de données en minutes]{Temps de calcul nécessaire à l'ajustement du modèle pour chacun des jeux de données en minutes}
```{r time-jDM-boral,echo=F,include=T}
library(dplyr)
load("~/Code/Report/data/jSDM_boral_sim.RData")
load("~/Code/Report/data/jSDM_boral_mosquito.RData")
load("~/Code/Report/data/jSDM_boral_eucalypts.RData")
load("~/Code/Report/data/jSDM_boral_frogs.RData")
load("~/Code/Report/data/boral_fungi.RData")
load("~/Code/Report/data/jSDM_fungi.RData")
result <- data.frame(matrix(NA,2,5),row.names=c("boral","jSDM "))
colnames(result) <- c("Simulation","Moustiques","Eucalyptus","Grenouilles","Champignons")
result[1,]=c(T_boral_sim, T_boral_Mosquito, T_boral_Eucalypts, T_boral_Frogs, T_boral_Fungi)
result[2,]=c(T_jSDM_block_sim, T_jSDM_block_Mosquito, T_jSDM_block_Eucalypts, T_jSDM_block_Frogs, T_jSDM_block_Fungi)
knitr::kable(result, row.names=T, digits=1,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 
On constate que les temps de calcul de jSDM sont largement inférieurs à ceux nécessaires à boral ce qui est dû aux méthodes d'inférence différentes ansi qu'à l'utilisation de Rcpp pour la construction de jSDM, qui permet l'intégration de fonction en C++ au sein du package. En effet le tirage selon des lois normales multivariées des paramètres par jSDM présente un gain de temps considérable par rapport à la méthode MCMC estimant chaque paramètre séparément utilisée par boral. 
\newpage
\begin{table}[H]\caption[RMSE obtenus  avec boral et jSDM pour les données simulées]{RMSE obtenus avec boral et jSDM pour les données simulées}
```{r RMSE-jSDM-boral, echo=F,include=T}
result <- data.frame(matrix(NA,1,2),row.names=  c("RMSE"))
colnames(result) <- c("boral","jSDM")
result$boral <- RMSE_boral_sim
result$jSDM <- RMSE_jSDM_block_sim
kable(result, row.names=T, digits=2,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 
Le RMSE associé à jSDM est trois fois inférieur à celui de boral ce qui indique que les résultats obtenus avec jSDM sur le jeu de données simulé sont bien plus proches de ceux attendus que les paramètres estimés avec boral. On peut l'expliquer par une convergence plus rapide de l'algorithme utilisé par jSDM dûe à l'utilisation de priors conjugués et au tirage des paramètres par espèce selon une loi jointe. 
\begin{table}[H]\caption[Déviances calculées à partir des paramètres estimés avec chacun des packages]{Déviances calculées à partir des paramètres estimés avec chacun des packages}
```{r deviance,echo=F,include=T}
library(knitr)
result <- data.frame(matrix(NA,2,5),row.names=c("boral", "jSDM"))
colnames(result) <- c("Simulation","Moustiques","Eucalyptus","Grenouilles","Champignons")
result[1,] <- c(Deviance_boral_sim, Deviance_boral_Mosquito, Deviance_boral_Eucalypts, Deviance_boral_Frogs, Deviance_boral_Fungi)
result[2,] <- c( mean(mod_jSDM_block_sim$mcmc.Deviance),  mean(mod_jSDM_block_Mosquito$mcmc.Deviance),  mean(mod_jSDM_block_Eucalypts$mcmc.Deviance),  mean(mod_jSDM_block_Frogs$mcmc.Deviance),  mean(mod_jSDM_block_Fungi$mcmc.Deviance))
kable(result, row.names=T, digits=0,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 
Les déviances obtenues avec jSDM sont bien inférieures à celles calculées avec les résultats de boral ce qui suggére que les modèles ajustés par jSDM correspondent mieux aux données. 

## Représentation des paramètres estimés pour les différents jeux de données 

\begin{figure}[H]
\caption[Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les données simulées]{Représentation des résultats obtenus avec jSDM en fonction de ceux estimés avec  boral pour les données simulées}
\centering
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-simulation-1.pdf}
\includegraphics[height=0.45\textheight, width=0.4\textwidth] 
{Illustrations/jSDM-boral-simulation-2.pdf}\\ \vspace{0.5cm}
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-simulation-3.pdf}  \includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-simulation-4.pdf}\\ 
\includegraphics[height=0.4\textheight, width=0.45\textwidth]{Illustrations/jSDM-boral-simulation-5.pdf} 
\end{figure} 
\begin{figure}[H]
\caption[Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les moustiques]{Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les moustiques}
\centering
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-mosquito-1.pdf} 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-mosquito-2.pdf}\\ 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-mosquito-3.pdf}  
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-mosquito-4.pdf}\\ 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-mosquito-5.pdf} 
\end{figure} 
\begin{figure}[H]
\caption[Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les eucalyptus]{Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les eucalyptus}
\centering
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-Eucalypts-1.pdf}
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-Eucalypts-2.pdf}\\ \vspace{0.3cm}
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-Eucalypts-3.pdf}  
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-Eucalypts-4.pdf}\\ \vspace{0.3cm} 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-Eucalypts-5.pdf} 
\end{figure} 
\begin{figure}[H]
\caption[Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les grenouilles]{Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les grenouilles}
\centering
 \includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-frogs-1.pdf} 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-frogs-2.pdf}\\ 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-frogs-3.pdf}  
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-frogs-4.pdf} \\
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-frogs-5.pdf} 
\end{figure}
\begin{figure}[H]
\caption[Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec boral pour les champignons]{Représentation des réultats obtenus avec jSDM en fonctions de ceux estimés avec  boral pour les champignons}
\centering
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-fungi-1.pdf}
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-fungi-2.pdf} \\ 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-fungi-3.pdf}  
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-fungi-4.pdf} \\ 
\includegraphics[height=0.45\textheight, width=0.4\textwidth]{Illustrations/jSDM-boral-fungi-5.pdf} 
\end{figure}
On constate que pour le jeux de données simulées les paramètres estimés par les deux packages sont très proches en revanche pour les jeux de données réels ils sont assez différents ce qui peut être dû à un nombre insuffisant d'espèces et donc d'observations pour estimer les effets sites correctement et à la difficulté d'estimer les variables latentes. 

# Application aux données collectées à Madagascar

## Description des données

On dispose des inventaires forestiers nationaux réalisés sur $753$ sites de l'île de Madagascar et répertoriant la présence ou l'absence de $555$ espèces végétales sur chacun de ces sites entre 1994 et 1996.  
 
Parmi les données climatiques et environnementales  disponibles sur le site \url{https://madaclim.cirad.fr} concernant l'ensemble de l'île de Madagascar à l'heure actuelle (interpolations de données observées représentatives des années 1950-2000),  on choisit d'utiliser les variables suivantes car elles ont un sens écologique qui les rend facilement interprétables et sont peu corrélées entre elles d'après l'article @Vieilledent2013.  
De plus on extrait les valeurs de ces variables climatiques correspondant aux coordonnées des placettes d'inventaires pour obtenir les données suivantes. 
\begin{table}[H]
\caption[Variables bioclimatiques considérées]{Variables bioclimatiques considérées affichées pour quelques sites : \\ 
Les températures (temp) et précipitations (prec) moyennes annuelles qui sont exprimées respectivement en $^\circ C\times 10$ et millimètres.\\
La saisonnalité des températures (sais\_temp) correspond à l'écart type des températures mensuelles multiplié par $100$ ainsi que la saisonnalité des précipitations (sais\_prec) sous la forme d'un coefficient de variation.\\
Le déficit hydrique climatique (cwd) annuel est calculé en fonction des précipitations et des évapotranspirations potentielles mensuelles (pet) qui sont définies comme la quantité d'évaporation qui se produirait en un mois si une source d'eau suffisante était disponible : \\$\mathrm{cwd}= \sum_{m=1}^{12}\min(0, \ \mathrm{prec}_m-\ \mathrm{pet}_m)$ , il est exprimé en millimètres.  \\
Les trois dernières colonnes correspondent aux coordonnées du site considéré en 
latitude (lat) et longitude (long) ainsi qu'à son identifiant (site).}
```{r site-data-clim, echo=F,include=F}
library(raster)
library(rgdal)
library(readr)
library(dplyr)
s <- stack("data/current.tif")
names(s) <- c(paste("tmin",1:12,sep=""),paste("tmax",1:12,sep=""),
              paste("prec",1:12,sep=""),paste("bio",1:19,sep=""),
              paste("pet",1:12,sep=""),"pet","cwd","ndm")
# get intersting covariables 
clim_var <- dropLayer(s, c(1:36,38,39,41:47,49,50,52:68,70))
names(clim_var) <- c("temp","prec","sais_temp","sais_prec","cwd")
# foresr inventory
trees <- read_csv("data/forest_inventory_Madagascar.csv")
# spatial points of each plot
longlat <- SpatialPoints(unique(cbind(trees$long,trees$lat)))
proj4string(longlat) <- CRS("+proj=longlat +ellps=clrk66")
# latlong to UTM38S projection 
xy <- spTransform(longlat, CRS("+init=epsg:32738"))
# extract climatic data on each plot
clim <-  extract(clim_var,xy)
clim2 <- clim^2
colnames(clim2)<-paste(colnames(clim),rep("2",ncol(clim)),sep="")
pos = unique(trees[,c("long","lat","plot")])
colnames(pos) <- c("long","lat","site")
data_clim <- cbind(clim,pos)
# order plot
ord_data_clim <- data_clim[sort(data_clim$site, index.return=TRUE)$ix,]
```
```{r head-site-data-clim, echo=F}
knitr::kable(head(ord_data_clim), row.names=F, digits=3,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table}
On considère également les carrés de ces variables climatiques afin d'effectuer un régression quadratique, plus adaptée pour ajuster un modèle de niche qu'une régression linéaire. On centre et on réduit ces variables afin de former une matrice de design $X$ telle que 
$X_i=(1,\mathrm{temp}_i, \mathrm{prec}_i,\mathrm{sais\_temp}_i, \mathrm{sais\_prec}_i,  \mathrm{cwd}_i,\mathrm{temp}_i^2, \mathrm{prec}_i^2,\mathrm{sais\_temp}_i^2, \mathrm{sais\_prec}_i^2, \mathrm{cwd}_i^2)$ pour $i=1,\ldots,753$.  
Les coordonnées des sites seront utilisées par la suite dans le cadre de l'interpolation spatiale et pour représenter spatialement les résultats. 

\newpage

## Estimation des paramètres et représentation des résultats 

### Représentation des réultats pour évaluer la convergence de l'algorithme

On ajuste un modèle joint de distribution des espèces de fonction de lien probit en considérant deux variables latentes à l'aide de la fonction *jSDM\_probit\_block()* du package jSDM à partir des données décrites précédemment, en effectuant $100 000$ itérations dont $90 000$ de burn-in et on retient $N_{samp}=1 000$ valeurs pour chaque paramètre du modèle que l'on va représenter en fonction du nombre d'itérations effectuées afin d'évaluer la convergence de l'algorithme de Gibbs.  
De plus on affiche une estimation de la densité des échantillons obtenus qui devrait correspondre aux distributions *a posteriori* définies et donc être de forme gaussienne.  
On met en évidence les moyennes des $N_{samp}$-échantillons en bleu, que l'on utilisera comme estimateur pour les paramètres. 
\begin{table}[H]\caption[Temps de calcul nécessaire à l'ajustement du modèle sur les données de Madagascar et nombre de paramètres à estimer]{Temps de calcul nécessaire à l'ajustement du modèle sur les données de Madagascar et nombre de paramètres à estimer}
```{r results-mada, echo=F, include=T}
library(dplyr)
load("data/mada_mod.RData")
nsp<-ncol(mod_all$model_spec$presences)
nplot<-nrow(mod_all$model_spec$presences)
p <- ncol(mod_all$model_spec$site_data)
T_all <- as.numeric(T_all,units="hours")
results <- data.frame(n_obs=nsp*nplot,n_param=(p+1)*nsp+2*nsp-1+2*nplot+nplot+1,ngibbs=as.integer(100000),"Temps"= T_all)
colnames(results)<- c("Nombre d'observations","Paramètres à estimer","Itérations effectuées","Temps de calcul (heures)")
knitr::kable(results, row.names=F, digits=0,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","basic"), full_width=FALSE)
```
\end{table} 
\begin{figure}[H]
 \caption[Traces et densités de la déviance du modèle]{Traces et densités de la déviance du modèle}
  \centering
\includegraphics[width=0.8\textwidth,height=0.25\textheight]{Illustrations/mada_deviance.jpeg}
\end{figure}
\begin{figure}[H]
 \caption[Traces et densités des effets espèces fixes $(\beta_{jk})_{j=2}^{k=0,\ldots,10}$ estimés pour la deuxième espèce]{Traces et densités des effets espèces fixes $(\beta_{jk})_{j=2}^{k=0,\ldots,10}$ estimés pour la deuxième espèce}
  \centering
\includegraphics[width=10cm,height=12cm]{Illustrations/mada_beta1_sp2.jpeg}
\includegraphics[width=10cm,height=12cm]{Illustrations/mada_beta2_sp2.jpeg}
\includegraphics[width=10cm,height=12cm]{Illustrations/mada_beta3_sp2.jpeg}
\end{figure}
\begin{figure}[H]
 \caption[Traces et densités des effets espèces fixes $(\lambda_{jq})_{j=1,2}^{q=1,2}$ estimés pour les deux premières espèces]{Traces et densités des effets espèces fixes $(\lambda_{jq})_{j=1,2}^{q=1,2}$ estimés pour les deux premières espèces}
  \centering
\includegraphics[width=10cm,height=10cm]{Illustrations/mada_lambda_sp1.jpeg}\\
\includegraphics[width=10cm,height=10cm]{Illustrations/mada_lambda_sp2.jpeg}
\end{figure}
Dans l'ensemble les traces et les densités des paramètres indiquent la convergence de l'algorithme. En effet on observe sur les traces que les valeurs oscillent autour de moyennes sans présenter de tendance croissante ou décroissante et on consate que les densités sont assez lisses et pour la plupart de forme gaussienne mise a part celle de l'effet espèce $\lambda_{11}$ ce qui est certainement dû à la façon d'imposer des valeurs positives à ce paramètre.
\begin{figure}[H]
 \caption[Traces et densités des variables latentes $W_1$ et $W_2$ estimées pour un site]{Trace et densité estimées des variables latentes $W_1$ et $W_2$ estimées pour un site}
  \centering
\includegraphics[width=0.8\textwidth,height=0.3\textheight]{Illustrations/mada_W.jpeg}
\end{figure} 
\begin{figure}[H]\caption[Trace et densité d'un effet site et de la variance associée aux effets sites estimés]{Trace et densité d'un effet site et de la variance associée aux effets sites estimés}
  \centering
\includegraphics[width=0.6\textwidth,height=0.25\textheight]{Illustrations/mada_rand_site.jpeg}\\
\includegraphics[width=0.6\textwidth,height=0.25\textheight]{Illustrations/mada_Valpha.jpeg}
\end{figure}  

\newpage

### Matrice de corrélation résiduelle entre les espèces estimée 

On ajuste le modèle avec les mêmes données bioclimatiques mais en considérant seulement les $50$ espèces qui sont présentes sur le plus de placettes d'inventaire afin de pouvoir représenter la matrice des corrélation résiduelle des probabilités d'occurence de ces $50$ espèces calculée de la même manière que dans les articles  @Warton2015 et @Tobler2019 à l'aide de la fonction *get_residual_corr()*, du package jSDM.
\begin{figure}[H]
 \caption[Matrice de corrélation entre les $50$ espèces les plus présentes estimée]{Matrice de corrélation entre les $50$ espèces les plus présentes estimée dont les coefficients sont les $(\rho_{ij})^{i=1,\ldots,50}_{j=1,\ldots, 50}$ qui sont calculés par $\rho_{i,j} = \dfrac{\Sigma_{ij}}{\sqrt{\Sigma _{ii}\Sigma _{jj}}}$ avec 
$\Sigma_{ij} = \begin{cases}
\lambda_i .\lambda_j' & \text{ si } i \neq j \\
\lambda_i .\lambda_j' + 1 & \text{ si } i=j
\end{cases}$, la matrice de variance covariance.\\}
  \centering
\includegraphics[width=1.0\textwidth,height=1.0\textwidth]{Illustrations/mada_mat_corr_50.png}
\end{figure}  
Cette matrice de corrélation résiduelle permet d'observer les corrélations positives ou négatives entre les espèces qui sont interprétables en terme d'influence positive ou négative de la présence d'un espèce sur la probabilité d'occurence d'une autre.

### Représentations spatiales des paramètres associés aux sites et des probabilités de présence estimées

\begin{figure}[H]
 \caption[Représentation spatiale des variables latentes $W_1$ et $W_2$ estimées pour chaque site]{Représentation spatiale des variables latentes $W_1$ et $W_2$ estimées pour chaque site}
  \centering
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{Illustrations/mada_W1.png}\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{Illustrations/mada_W2.png}
\end{figure}
\begin{figure}[H]\caption[Représentation spatiale des effets sites $(\alpha_i)_{i=1,\ldots,753}$ estimés]{Représentation spatiale des effets sites estimés}
  \centering
\includegraphics[width=0.5\textwidth,height=0.5\textheight]{Illustrations/mada_site_effect.png}
\end{figure} 
\begin{minipage}[l]{0.5\textwidth}
\begin{figure}[H]\caption[Représentation spatiale des probabilités de présence estimées pour l'espèce Ocotea laevis]{Représentation spatiale des probabilités de présence estimées pour l'espèce Ocotea laevis}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_proba_sp1.png}
\end{figure} 
\end{minipage}
\begin{minipage}[r]{0.5\textwidth}
\begin{figure}[H]\caption[Représentation spatiale des occurences observées de l'espèce Ocotea laevis]{Représentation spatiale des occurences observées de l'espèce Ocotea laevis}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_presence_sp1_obs.png}
\end{figure} 
\end{minipage}

### Estimation de la richesse spécifique pour les placettes d'inventaire et comparaison à celle observée

La richesse spécifique aussi appelée diversité $\alpha$ reflète le nombre d'espèces coexistant dans un milieu donné, on l'estime en additionnant les probabilités de présence estimées.  
\begin{minipage}[l]{0.5\textwidth}
\begin{figure}[H] \caption[Représentation spatiale de la richesse spécifique estimée pour chaque site]{Représentation spatiale de la richesse spécifique estimée pour chaque site par $\widehat{R_i}=\sum\limits_ {j=1}^{555} \widehat{\theta_{ij}}$.}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness.png}
\end{figure} 
\end{minipage}
\begin{minipage}[r]{0.5\textwidth}
\begin{figure}[H] \caption[Représentation spatiale de la richesse spécifique observée pour chaque site]{Représentation spatiale de la richesse spécifique observée pour chaque site calculée par $R_i=\sum\limits_ {j=1}^{555} y_{ij}$}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness_obs.png}
\end{figure} 
\end{minipage}
\begin{figure}[H]\caption[Représentation richesse spécifique estimée en fonction de celle observée]{Représentation richesse spécifique estimée en fonction de celle observée}
  \centering
\includegraphics[width=0.4\textwidth,height=0.4\textheight]{Illustrations/mada_species_richness_obs_fit.png}
\end{figure}

## Comparaison des effets sites obtenus avec différentes méthodes d'interpolation spatiale

La présence d'une structure spatiale où les observations proches les unes des autres sont plus semblables que celles qui sont éloignées (auto-corrélation spatiale) est une condition préalable à l'application de la géostatistique et d'après les représentations spatiales précédentes elles semble être remplie. 
On est ainsi en mesure d'interpoler les effets sites pour l'ensemble de l'île à partir de ceux estimés pour les placettes d'inventaire à l'aide du package gstat selon trois méthodes d'interpolation spatiales afin de choisir celle qui donne les meilleurs résultats en s'inspirant de l'article @Robinson2006. 
D'une part on utilise la méthode déterministe de pondération par distance inverse, nommée **IDW** pour l'interpolation multivariée à partir de l'ensemble connu de points dispersés. Les valeurs attribuées à des points inconnus sont calculées avec une moyenne pondérée des valeurs disponibles aux sites connus qui fait appel à l'inverse de la distance par rapport à chaque point connu lors de l'attribution des poids.  

D'autre part on procède par krigeage ordinaire (**OK**) ce qui consiste à considérer les valeurs des sites inconnus comme une combinaison linéaire des valeurs connues dont les coefficients $\lambda_i$ sont estimés en minimisant la variance $\sigma^2_e$ de l'erreur d'estimation théorique définie par $e=Z_v -Z_v^*$, avec $Z_v$ la variable aléatoire que l'on veut estimer et $Z_v^*=\sum_{i=1^n}\lambda_i Z_i$ son estimateur, où les $(Z_i)_{i=1}^n$ sont les valeurs des sites connus.  
La variance $\sigma^2_e$ dépend des coefficients ainsi que du variogramme experimental qui tient compte non seulement de la distance entre les données et les points d'estimation, mais également des distances entre les données deux-à-deux.
En effet le variogramme expérimental mesure le degré moyen de dissimilitude entre des valeurs non échantillonnées et une valeur connue voisine et peut donc représenter l'auto-corrélation à différentes distances.  
La valeur du variogramme expérimental pour une distance de séparation de $h$ est $\hat{\gamma}(h)= \frac{1}{2N(h)}\sum\limits_{i=1}^{N(h)}(z(x_i)-z(x_i+h))^2$ où $N(h)$ est le nombre de paires de données séparées de la distance $h$. Si les valeurs de $z(x_i)$ et $z(xi + h)$ sont auto-corrélées, le résultat sera faible par rapport à une paire de points non corrélés. A partir du variogramme expérimental un modèle approprié par exemple exponentiel est ensuite ajusté, habituellement par les moindres carrés pondérés dont les paramètres seront ensuite utilisés dans la procédure de krigeage.    
Cette méthode linéaire est sans biais et de variance minimale par construction, de plus elle tient compte de la taille du champ a estimer et de la continuité spatiale du phénomène étudié.   

Finalement on applique la méthode **TPS** pour thin plate spline pour laquelle une fonction thin plate spline en deux dimensions est ajustée sur les coordonnées et les valeurs des points connus afin d'interpoler les valeurs non observées en fonction de leurs positions. Les fonction splines qui sont définis par morceau à l'aide de différents polynômes donnent de bons résultats sur des surfaces légèrement variables mais ne sont souvent pas appropriées lorsqu'il y a des variations importantes entre les valeurs à une courte distance comme c'est le cas pour nos effets sites estimés.

\begin{table}[H]\caption[RMSE obtenus par validation croisée entre les effets sites estimés et ceux prédits par différentes méthodes d'interpolation]{RMSE obtenus par validation croisée entre les effets sites estimés et ceux prédits par interpolation avec OK, TPS et IDW.\\
Dans le cadre de la validation croisée, on divise l'échantillon original d'effets sites estimés en $k=5$ échantillons, puis on sélectionne un des $k$ échantillons comme ensemble d'apprentissage et les $k-1$ autres échantillons constitueront l'ensemble de validation. On répète $k$ fois cette opération afin qu'en fin de compte chaque sous-échantillon ait été utilisé exactement une fois pour la phase d'apprentissage qui consite à ajuster les modèles correspondant à chaque méthode d'interpolation. Puis les effets sites sont interpolés suivant ces modèles pour les localisations correspondant à l'ensemble de validation.\\
Enfin on calcule le RMSE entre les valeurs estimées des effets sites appartenant à l'ensemble de validation $(\widehat{\alpha_i})_{i=1,\ldots,n_v}$ et celles interpolées $(\widetilde{\alpha_i})_{i=1,\ldots,n_v}$ de la forme $RMSE=\sqrt{\sum\limits_{1\leq i\leq n_v} \frac{1}{n_v}\left(\widehat{\alpha_i}-\widetilde{\alpha_i}\right)^2}
$ avec $n_v$ le nombre d'éléments de l'ensemble de validation correspondant au nombre de sites sur lesquels on a collecté des données moins ceux utilisés pour l'apprentissage.\\
La dénomination Ensemble correspond aux résultats obtenus en calculant la moyenne des effets sites interpolés par OK, TPS et IDW, pondérée par le RMSE de la méthode considérée sur la somme des RMSE correspondant à chacune des méthodes.\\
Chaque effet site calculé pour Ensemble est donc de la forme $\widetilde{\alpha_i}^E = \frac{RMSE^{TPS}}{SRMSE}\widetilde{\alpha_i}^{TPS} + \frac{RMSE^{OK}}{SRMSE}\widetilde{\alpha_i}^{OK} + \frac{RMSE^{IDW}}{SRMSE}\widetilde{\alpha_i}^{IDW}$ avec $SRMSE=RMSE^{TPS}+RMSE^{OK}+RMSE^{IDW}$.\\
La moyenne de $k$ RMSE obtenus pour chaque méthode est présentée dans le tableau.}
```{r results-cv, echo=F, include=T}
library(dplyr)
cv_alphas<-read.csv("~/Code/Report/data/cv_alphas.csv")
cv_alphas <- cv_alphas[,1:4]
colnames(cv_alphas)<- c("IDW","OK","TPS","Ensemble")
rownames(cv_alphas)<-c("RMSE")
knitr::kable(cv_alphas, row.names=T, digits=3,booktabs=TRUE,align = 'c') %>%
kableExtra::kable_styling(latex_options=c("HOLD_position","basic"), full_width=FALSE)
```
\end{table}

\begin{figure}[H]
 \caption[Comparaison des cartes obtenues pour les effets sites par différentes méthodes d'interpolation]{Comparaison des cartes obtenues pour les effets sites par une interpolation avec la méthode du krigeage ordinaire (OK), de l'inverse de la distance pondéré (IDW) et de thin plate spline (TPS)}
  \centering
\includegraphics[width=0.8\textwidth,height=0.45\textheight]{Illustrations/comparaison_site_effect.png}
\end{figure}

On choisira donc d'interpoler les variables latentes et les effets sites estimés pour les placettes d'inventaires par krigeage ordinaire car cette méthode présente un RMSE inférieur aux autres.  


## Résultats de l'interpolation spatiale par krigeage ordinaire

\begin{figure}[H]
 \caption[Interpolation spatiale des variables latentes par krigeage ordinaire]{Interpolation spatiale des variables latentes par krigeage ordinaire}
  \centering
\includegraphics[width=0.8\textwidth,height=0.35\textheight]{Illustrations/mada_W_OK.png}
\end{figure} 

Les paramètres interpolés permettent de calculer les probabilités de présence pour chacune des espèces en fonction des variables climatiques définies précédemment dont les valeurs sont connues pour l'ensemble de l'île et sont centrées et réduites pour le calcul. 

\begin{figure}[H]
 \caption[Probabilités de présence interpolées pour deux espèces]{Probabilités de présence interpolées pour deux espèces}
  \centering
\includegraphics[width=30cm,height=10cm]{Illustrations/mada_proba_OK.png}
\end{figure} 

## Estimation de la richesse spécifique à Madagascar

On additionne les probabilités de présence interpolées pour chacune des espèces afin d'obtenir la richesse spécifique.   
Cependant le modèle utilisé ne prend pas en compte la présence humaine qui se manifeste en particulier par la déforestation de l'île, on utilise donc les données sur le couvert forestier restant en 2000 provenant de l'article @Vieilledent2018 afin de remplacer par des valeurs nulles les richesses spécifiques interpolées à des endroits où on sait qu'il n'y a pas de forêt.  

\begin{figure}[H]
 \caption[Richesse spécifique interpolée sur l'ensemble de l'île et restreinte au couvert forestier]{Richesse spécifique interpolée sur l'ensemble de l'île et restreinte au couvert forestier}
  \centering
\includegraphics[width=0.5\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness_OK.png}
\includegraphics[width=0.5\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness_OK_forest.png}
\end{figure} 

\newpage

## Estimation de la diversité $\beta$ à Madagascar

La diversité $\beta$ est une mesure de la biodiversité qui consiste à comparer la diversité des espèces entre écosystèmes ou le long de gradients environnementaux, en utilisant le nombre de taxons qui sont uniques à chacun des écosystèmes.  

Afin d'estimer cet indicateur, on procède de la même façon que dans l'article @Allnutt2008 en effectuant une ACP normée sur les probabilités de présence des espèces interpolées pour chaque pixel de l'image affichée. On utilise les coordonnées obtenues pour les trois premiers axes de l'ACP qui reflètent la composition de la communauté d'espèces occupant probablement le pixel correspondant. Ces coordonnées sont mises à l'échelle $[0,255]$ afin d'être représentables par des niveaux de couleur rouge pour le premier axe, verte pour le deuxième et bleue pour le troisième, l'association de ces trois niveaux de couleur détermine la coloration de chaque pixel de la carte de diversité $\beta$ affichée. Par conséquent une différence de couleur entre deux pixels indique que les espèces présentes ne sont pas les mêmes tandis que des pixels de couleur identiques hébergent des communautés d'espèces similaires.  

De la même manière que précédemment, on restreint les valeurs obtenues pour la diversité $\beta$ au couvert forestier restant en 2000 provenant de l'article @Vieilledent2018 en remplaçant par des valeurs nulles les résultats obtenus à des endroits où on sait qu'il n'y a pas de forêt.  

On utilise le modèle ajusté sur les 50 espèces les plus présentes pour estimer la diversité $\beta$ après avoir interpolé les paramètres estimés pour les placettes d'inventaire par krigeage ordinaire. On n'est pas en mesure d'effectuer l'ACP avec toutes les espèces en raison du temps de calcul et de la mémoire nécessaire qui sont trop importants. 

\begin{figure}[H]
 \caption[Diversité $\beta$ interpolée sur l'ensemble de l'île et restreinte au couvert forestier]{Diversité $\beta$ interpolée sur l'ensemble de l'île et restreinte au couvert forestier connu en 2000}
  \centering
\includegraphics[width=0.45\textwidth,height=0.45\textheight]{Illustrations/mada_div_beta.png}
\includegraphics[width=0.45\textwidth,height=0.45\textheight]{Illustrations/mada_div_beta_forest.png}
\end{figure} 

\newpage
\pagestyle{simple}

\section*{Discussion}
\addcontentsline{toc}{section}{Discussion}

Dans un premier temps, on relève que sur les cartes de diversité $\alpha$ obtenues, le centre de l'île présente une grande richesse spécifique ce qui est incohérent avec l'absence de forêt avérée à cet endroit. Ces résultats aberrants peuvent provenir d'une erreur de ma part lors de la manipulation des données ou de l'utilisation des différentes méthodes d'interpolation, que je n'ai pas encore trouvée ou bien de la méthode d'interpolation en elle même et par exemple du variogramme utilisé car ces valeurs incohérentes sont situées assez loin des placettes d'inventaires. 

De plus il serait préferable de vérifier la convergence de l'algorithme autrement qu'en observant juste les traces et densité des résultats obtenus, on pourrait pas exemple générer différentes chaînes de Markov en initialisant les paramètres par des valeurs différentes pour chacune puis calculer l'indice de Gelman Rubin en fonction des variances intra et inter chaînes estimées qui si il est proche 1 suggére que l'algorithme a convergé.  

Par la suite afin de compléter l'analyse des données concernant Madagascar, on pourra utiliser les mêmes méthodes et les paramètres estimés précédemment afin de réaliser des cartes de diversité $\alpha$ et $\beta$ à partir des données climatiques prévisionnelles pour les années 2050 et 2080, disponibles sur le site \url{https://madaclim.cirad.fr}, afin d'évaluer l'évolution de la biodiversité en fonction des changements climatiques prédits et ainsi de mettre en évidence de lieux refuges de la biodiversité.  

D'autre part le package jSDM que j'ai implémenté est pour l'instant assez limité, il ne permet d'ajuster que deux types de modèles assez contraints avec les fonction *jSDM_probit_block()* et *jSDM_binomial()*, la prédiction n'est possible que sur les placettes d'inventaire et les données en format long ne sont pas prises en charge.  

Il est prévu d'enrichir le package afin qu'il permette l'ajustement de différents types de modèles avec des effets aléatoires ou fixes et avec ou sans variables latentes ainsi que des modèles intégrant des traits spécifiques tels que la surface foliaire spécifique (SLA) comme variables explicatives pour lesquels une fonction est en cours de développement.  

L'utilisation de données en format long, c'est à dire sous forme de vecteur de taille $I\times J$ plutôt que de matrices avec autant de colonnes que d'espèces et autant de lignes que de sites serait plus conventionnel et permettrait la gestion de données manquantes au sein des inventaires forestiers, on modifiera donc cet aspect de la fonction *jSDM_probit_block()*.   

De plus on a relevé qu'un nombre insuffisant d'observations et en particulier d'espèces détériore gravement la qualité de l'estimation des effets sites, on devrait donc préconiser un nombre minimum d'espèces en fonction du nombre de sites considérés pour utiliser la fonction.   

On a expliqué que le tirage en bloc des effets espèces fixes présente des avantages mais il engendre des difficultés pour imposer proprement les contraintes sur les effets espèces liés aux variables latentes ce qui pourrait être amélioré en générant séparément les $\widehat{\lambda_{jl}}$ pour $j=1,\ldots,J$ et $l=1,\ldots,q$ pour lesquels on utiliserait les mêmes priors que boral.   

Enfin il est essentiel d'intégrer au package un fonction permettant de prédire des probabilités de présence pour des sites sur lesquels on ne dispose pas de données de présence absence, pour ce faire j'ai envisagé deux méthodes explicitées dans les articles @Guelat2018 @Latimer2006 afin d'intégrer une auto-corrélation spatiale dans le modèle.  

D'une part j'ai développé une fonction ajustant un modèle gaussien auto-régressif conditionnel (CAR) intrinsèque en utilisant une grille sur l'ensemble du territoire considéré dont chacune des cellules possède au plus huit voisines. On estimera ainsi les valeurs des effets sites et des variables latentes pour chacune des cellules en fonction de ceux estimés pour les cellules voisines.  
En effet dans le contexte des modèles de répartition des espèces, on suppose que la présence ou l'absence d'une espèce à un endroit est associée à sa présence ou son absence dans le voisinage. Afin de prendre en compte les voisinages, les distributions *a priori* des paramètres liés aux sites sont centrées sur la moyenne des valeurs prises par ces paramètres dans les cellules voisines et leurs variances dépendent du nombre de cellules partageant des frontières avec la cellule considérée. Cependant cette méthode induit un temps de calcul important et présente des difficultés à converger car les paramètres à estimer sont très nombreux en raison du nombre conséquent de cellules constituant la grille utilisée.   

D'autre part j'ai essayé d'intégrer un 2D splines dans le modèle en redéfinissant les effets sites par le produit d'une matrice calculée en fonction de la distance du site par rapport à des noeuds répartis uniformément sur le territoire étudié, et de paramètres à estimer qui sont aussi nombreux que les noeuds choisis. On ajoute également les coordonnées des sites parmi les variables explicatives du modèle ce qui induit deux paramètres supplémentaires à estimer.  

Finalement ces fonctions intégrant une auto-corrélation spatiale dans le modèle, qui rendraient possible la prédiction sur des sites non observés sont implémentées mais ne sont pas abouties, en effet les résultats obtenus ne sont pas satisfaisants pour l'instant.

\newpage
\section*{Bibliographie}
\addcontentsline{toc}{section}{Bibliographie}
<div id="refs"></div>

\newpage
\section*{Annexes}
\addcontentsline{toc}{section}{Annexe}

\subsection*{Fonction utilisée pour le modèle probit}

```{r Rcpp_jSDM_probit_block, engine="Rcpp", eval=F}
#include <RcppArmadillo.h>
#include <gsl/gsl_rng.h>
#include <gsl/gsl_randist.h>
#include <gsl/gsl_cdf.h>
#include <cmath>
#include "Rcpp_jSDM_useful.h"
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::depends(RcppGSL)]]
using namespace arma;
using namespace std;
/* ************************************************************ */
/* Gibbs sampler function */
// [[Rcpp::export]]
Rcpp::List Rcpp_jSDM_probit_block(const int ngibbs, int nthin, int nburn, 
                                  arma::umat Y, 
                                  arma::umat T, 
                                  arma::mat X,
                                  arma::mat param_start,
                                  arma::mat Vparam,
                                  arma::vec muparam,
                                  arma::mat VW,
                                  arma::mat W_start,
                                  arma::vec alpha_start,
                                  double Valpha_start,
                                  double shape,
                                  double rate,
                                  const int seed,
                                  const int verbose) {
  
  // Initialize random number generator 
  gsl_rng *s = gsl_rng_alloc(gsl_rng_mt19937);
  gsl_rng_set(s, seed);
  
   // Defining and initializing objects
  // Redefining constants 
  const int NGIBBS = ngibbs;
  const int NTHIN = nthin;
  const int NBURN = nburn;
  const int NSAMP = (NGIBBS-NBURN)/NTHIN;
  const int NSITE = Y.n_rows;
  const int NP = X.n_cols;
  const int NSP = Y.n_cols;
  const int NL = W_start.n_cols; 
  
  // Declaring new objects to store results 
  /* Parameters */
  arma::Cube<double> param; param.zeros(NSAMP, NSP, NP+NL);
  arma::Cube<double> W; W.zeros(NSAMP, NSITE, NL);
  arma::mat alpha; alpha.zeros(NSAMP, NSITE);
  arma::vec Valpha; Valpha.zeros(NSAMP);
  /* Latent variable */
  arma::mat probit_theta_pred; probit_theta_pred.zeros(NSITE, NSP);
  arma::mat Z_latent; Z_latent.zeros(NSITE, NSP);
  /* Deviance */
  arma::vec Deviance; Deviance.zeros(NSAMP);
  
  // Initializing running parameters 
  //  mat of species effects parameters and coefficients for latent variables (nl+np,nsp)
  arma::mat param_run = param_start;
  // alpha vec of sites effects (nsite)
  arma::vec alpha_run = alpha_start;
  double Valpha_run = Valpha_start;
  // w latent variables (nsite*nl)
  arma::mat W_run = W_start;
  // Z latent (nsite*nsp)
  arma::mat Z_run; Z_run.zeros(NSITE,NSP);
  // probit_theta_ij = X_i*beta_j + W_i*lambda_j + alpha_i
  arma::mat probit_theta_run; probit_theta_run.zeros(NSITE,NSP);
  // data 
  arma::mat data = arma::join_rows(X,W_run);
  // Message
  Rprintf("\nRunning the Gibbs sampler. It may be long, please keep cool :)\n\n");
  R_FlushConsole();
  
  ///////////////////////////////////////////////////////////////////////////////////////
  //%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  // Gibbs sampler 
  
  for (int g=0; g < NGIBBS; g++) {
    
    // latent variable Z 
    for (int j=0; j<NSP; j++) {
      for (int i=0; i<NSITE; i++) {
        // Actualization
        if (Y(i,j) == 0) {
          Z_run(i,j) = rtnorm(s, R_NegInf, 0, probit_theta_run(i,j), 1);
        } else {
          Z_run(i,j) = rtnorm(s, 0, R_PosInf, probit_theta_run(i,j), 1);
        }
      } // loop on sites
    }// loop on species
  
    // mat param: Gibbs algorithm 
    // Loop on species
    for (int j=0; j<NSP; j++) {
      // small_v
      arma::vec small_v = inv(Vparam)*muparam + data.t()*(Z_run.col(j) - alpha_run);
      // big_V
      arma::mat big_V = inv(inv(Vparam)+data.t()*data);
      // Draw in the posterior distribution
      arma::vec param_prop = arma_mvgauss(s, big_V*small_v, chol_decomp(big_V));
      
      // constraints on lambda
      for (int l=0; l<NL; l++) {
        if (l > j) {
          param_prop(NP+l) = 0;
        }
        if ((l==j) & (param_prop(NP+l) < 0)) {
          param_prop(NP+l) = param_run(NP+l,j);
        }
      }
      param_run.col(j) = param_prop;
    }// loop on species
    
    
    /////////////////////////////////////////////
    // mat latent variable W: Gibbs algorithm //
    
    // Loop on sites
    for (int i=0; i<NSITE; i++) {
      arma::mat beta_run = param_run.submat(0,0,NP-1,NSP-1);
      arma::mat lambda_run = param_run.submat(NP,0,NP+NL-1,NSP-1);
      // big_V
      arma::mat big_V = inv(inv(VW)+lambda_run*lambda_run.t());
      
      // small_v
      arma::vec small_v =lambda_run*(Z_run.row(i)-X.row(i)*beta_run-alpha_run(i)).t();
      
      // Draw in the posterior distribution
      arma::vec W_i = arma_mvgauss(s, big_V*small_v, chol_decomp(big_V));
      W_run.row(i) = W_i.t();
    }
    
    data = arma::join_rows(X, W_run);
    
    //////////////////////////////////
    // vec alpha : Gibbs algorithm //
    
    // Loop on sites 
    double sum = 0.0;
    for (int i=0; i<NSITE; i++) {
      // small_v
      double small_v = arma::sum(Z_run.row(i)-data.row(i)*param_run);
      // big_V
      double big_V = 1/(1/Valpha_run + NSP);
      
      // Draw in the posterior distribution
      alpha_run(i) = big_V*small_v + gsl_ran_gaussian_ziggurat(s, std::sqrt(big_V));
      sum += alpha_run(i)*alpha_run(i);
    }
    // Valpha
    double shape_posterior = shape + 0.5*NSITE;
    double rate_posterior = rate + 0.5*sum;
    Valpha_run = rate_posterior/gsl_ran_gamma_mt(s, shape_posterior, 1.0);
    // Deviance 
    // logLikelihood
    double logL = 0.0;
    for ( int i = 0; i < NSITE; i++ ) {
      for ( int j = 0; j < NSP; j++ ) {
        // probit(theta_ij) = X_i*beta_j + W_i*lambda_j + alpha_i 
        probit_theta_run(i,j) = arma::as_scalar(data.row(i)*param_run.col(j) + alpha_run(i));
        // link function probit is the inverse of N(0,1) repartition function 
        double theta = gsl_cdf_ugaussian_P(probit_theta_run(i,j));
        /* log Likelihood */
        logL += R::dbinom(Y(i,j), T(i,j), theta, 1);
      } // loop on species
    } // loop on sites
    // Deviance
    double Deviance_run = -2 * logL;
    
    // Output
    if (((g+1)>NBURN) && (((g+1)%(NTHIN))==0)) {
      int isamp=((g+1)-NBURN)/(NTHIN);
      for ( int j=0; j<NSP; j++ ) {
        param.tube(isamp-1,j) = param_run.col(j);
        for ( int i=0; i<NSITE; i++ ) {
          W.tube(isamp-1,i) = W_run.row(i);
          Z_latent(i,j) += Z_run(i,j) / NSAMP; // We compute the mean of NSAMP values
          probit_theta_pred(i,j) += probit_theta_run(i,j)/NSAMP;        
        }
      }
      alpha.row(isamp-1) = alpha_run.t();
      Valpha(isamp-1) = Valpha_run;
      Deviance(isamp-1) = Deviance_run;
    }
    
    //////////////////////////////////////////////////
    // Progress bar
    double Perc=100*(g+1)/(NGIBBS);
    if (((g+1)%(NGIBBS/100))==0 && (verbose==1)) {  
      Rprintf("*");
      R_FlushConsole();
      //R_ProcessEvents(); for windows
      if (((g+1)%(NGIBBS/10))==0) {
        Rprintf(":%.1f%% \n",Perc);
        R_FlushConsole();
        //R_ProcessEvents(); for windows
      }
    } 
    ///////////////////
  // User interrupt //
    R_CheckUserInterrupt(); // allow user interrupts 	    
  } // Gibbs sampler
  // Free memory
  gsl_rng_free(s);
  // Return results as a Rcpp::List
  Rcpp::List results = Rcpp::List::create(Rcpp::Named("param") = param,
                                          Rcpp::Named("W") = W,
                                          Rcpp::Named("alpha") = alpha,
                                          Rcpp::Named("Valpha") = Valpha,
                                          Rcpp::Named("Deviance") = Deviance,
                                          Rcpp::Named("Z_latent") = Z_latent,
                                          Rcpp::Named("probit_theta_pred") =  probit_theta_pred);  
  return results;
} // end Rcpp_jSDM_probit_block
```
