---
title: "Développement d’un modèle joint de distribution des espèces pour la réalisation d’une carte de biodiversité à Madagascar"
author: "Jeanne Clément"
date: "Rapport de stage, Février à Août 2019"
output:
  pdf_document :
    latex_engine : xelatex
    fig_caption : yes
    pandoc_args: ["--number-sections"]
header-includes: 
  - \usepackage{upgreek}
  - \usepackage{easybmat}
  - \usepackage{float}
  - \usepackage{fancyhdr}
  - \usepackage{hyperref}
  - \usepackage[frenchb]{babel}
  - \usepackage{amsmath,amssymb,amsthm}
  - \usepackage{graphicx}
  - \usepackage[labelfont=bf,textfont=sl,tableposition=top,small]{caption}
  - \usepackage{enumitem}
  - \usepackage{dsfont}
  - \usepackage{bbm}
  - \usepackage{answers}
  - \usepackage{xassoccnt}

bibliography: Biblio_master.bib
geometry: left=1.4cm,right=1.4cm,top=1.5cm,bottom=0.3cm
fontsize : 10pt
---
\renewcommand\UrlFont{\color{blue}\rmfamily\itshape}
\newtheorem{prop}{Proposition}
\RemoveFromReset{prop}{section}
\AddToReset{prop}{subsubsection}
\renewcommand{\theprop}{\thesubsubsection .\arabic{prop}}
\theoremstyle{definition}
\newtheorem{defn}{Définition}
\renewcommand{\thedefn}{\thesubsubsection .\arabic{dfn} }
\newtheorem{dem}{Preuve}
\RemoveFromReset{dem}{section}
\AddToReset{dem}{subsubsection}
\renewcommand{\thedem}{\thesubsubsection.\arabic{dem}}
\newtheorem{thm}{Théorème}
\renewcommand{\thethm}{\thesubsubsection.\arabic{thm}}
\renewcommand{\contentsname}{Sommaire}
\renewcommand{\listtablename}{Liste des tableaux}
\renewcommand{\listfigurename}{Liste des figures}
\renewcommand{\baselinestretch}{1.5}
\fancypagestyle{simple}{\rhead{\thepage} \chead{} \lhead{} \cfoot{}}
\renewcommand{\headrulewidth}{0pt}

\thispagestyle{empty}
\begin{center}

Enseignant référent : Benoite De Saporta  

Encadrant : Ghislain Vieilledent  

\vspace{0.5cm}

```{r illustration, echo=FALSE, include=T, out.width='90%'}
knitr::include_graphics('Illustrations/foret.jpg')
```

\vspace{0.5cm}

Master Maths-Biostatistique  

Université Montpellier 2  

UMR AMAP - Montpellier  

\vspace{1cm}

\includegraphics[height=1.7cm, width=1.7cm]{Illustrations/logo_UM.jpg}
\includegraphics[height=2cm, width=2cm]{Illustrations/logo-AMAP.png}
\includegraphics[height=1.3cm]{Illustrations/titre-long.png}
\includegraphics[height=3.1cm, width=3.1cm]{Illustrations/Logo-Cirad.png}
\end{center}

```{r options, echo=FALSE,include=F}
library(Rcpp)
library(RcppArmadillo)
library(RcppGSL)
library(knitr)
library(kableExtra)
knit_engines$get("Rcpp")
knit_engines$set("Rcpp")
opts_chunk$set(echo=TRUE, cache=FALSE,
               #results="hide", 
               warning=FALSE,
               message=FALSE, highlight=TRUE,
               fig.show="hide", size="small",
               fig.align="center",
               tidy=FALSE)
options(knitr.kable.NA="-")
```

\newpage
\thispagestyle{empty}
\section*{Remerciements}

J'aimerai adresser mes plus sincères remerciements à G. Vieilledent qui m'a encadrée et conseillée durant ce stage riche en découvertes puisque le language C++, la construction de packages R ainsi que les modèles joints de distribution des espèces m'étaient inconnus. Il m'a beaucoup appris et encouragée à trouver des solutions par moi même. Je remercie également les chercheurs et autres stagiaires de l'UMR AMAP pour leur accueil chaleureux et leur bonne humeur communicative qui font du laboratoire un cadre de travail idéal et tout particulièrement G. Le Moguedec qui fut une référence précieuse en statistiques ainsi que l'instigateur de pic-niques au lac du Crès qui nous ont bien aidé à supporter la canicule. 

\newpage
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables

\newpage
\setcounter{page}{1} 
\thispagestyle{simple}
\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

J'ai effectué mon stage au sein de l'UMR AMAP (botAnique et Modélisation de l'Architecture des Plantes et des végétations), qui se trouve à Montpellier. Il s'agit d'une unité interdisciplinaire hébergée par le Cirad ou « Centre de Coopération Internationale en Recherche Agronomique pour le Développement», qui mène des recherches sur les plantes et les végétations, dans le but de prévoir la réponse des écosystèmes aux forçages environnementaux.  

Ce stage s'inscrit dans le cadre du projet BioSceneMada qui vise à fournir des scénarios d'évolution de la biodiversité sous l’eﬀet conjoint du changement climatique et de la déforestation à Madagascar. Pour ce faire, plusieurs jeux de données sur la biodiversité ont été collectés et regroupés pour diﬀérents groupes taxonomiques (mammifères, oiseaux, reptiles, amphibiens, arbres, plantes herbacées, invertébrés), parmi lesquels j'ai utilisé des inventaires forestiers répertoriant l'absence ou la présence d'espèces d'arbres sur différents sites de l'île ainsi que des variables bioclimatques afin d'ajuster un modèle joint de distribution des espèces permettent d’estimer la niche des espèces, de prédire leur distribution, tout en prenant en compte les intéractions entre espèces (@Warton2015).  
Dans un premier temps j'ai implémenté différents échantillonneurs de Gibbs en C++ permettant d’estimer les paramètres de modèles joints de distribution des espèces (JSDM) comportant des variables latentes, à l'aide du package Rcpp. La construction du package R \url{https://ecology.ghislainv.fr/jSDM/} autour de l'une de ces fonctions ainsi que sa présentation à la conférence useR 2019 ont constitué une partie importante de mon stage. 
L'ajustement d'un JSDM sur des données d’inventaires forestiers collectées à Madagascar
ainsi que des variables climatiques et environnementales, m'a permis d’obtenir des carte reflétant la biodiversité sur l'île afin de par la suite identiﬁer des zones refuges de la biodiversité sous l’eﬀet du changement climatique en utilisant les variables bioclimatiques fournies par les scénarios du GIECC. 
Ces résultats seront utilisés pour des préconisations de gestion de la biodiversité dans le cadre du projet BioSceneMada.  

\newpage
\pagestyle{headings}

# Définition des modèles joints de distribution des espèces envisagés \quad

Les données dont on dispose pour ajuster ce type de modèle sont les réalisations d'une variable réponse,  
$Y=(y_{ij})^{i=1,\ldots,I}_{j=1,\ldots,J}$ telle que :

$$y_{ij}=\begin{cases}
    0 & \text{ si l'espèce $j$ est absente du site $i$}\\
    1 &  \text{ si l'espèce $j$ est présente sur le site $i$,}
    \end{cases}$$
ainsi que de variables explicatives $X=(X_i)_{i=1,\ldots,I}$ avec $X_i=(X_{i1},\ldots,X_{ip})\in \mathbb{R}^p$ où $p$ est le nombre de variables bioclimatiques considérées pour chaque site.  
On note $\theta_{ij}$, la probabilité de présence de l'espèce $j$ sur le site $i$.

L'article @Warton2015 développe deux approches hiérarchiques  pouvant être utilisées à la spécification d’un modèle joint de distribution des espèces.

## Modèle linéaire mixte généralisé (GLMM) 

D'une part on pourrait utiliser un modèle linéaire mixte généréralisé **(GLMM)** de la forme : 
$$g(\theta_{ij}) =\alpha_i + \beta_{j0} + X_i\beta_j + u_{ij},$$
$$y_{ij} \ | \ u_{ij}, \alpha_i \sim \mathcal{B}ernoulli(\theta_{ij}),$$
$$u_i \sim \mathcal{N}_J(0_{\mathbb{R}^J},\Sigma) \ iid,$$
$$\alpha_i \sim \mathcal{N}(0, V_{\alpha}) \ iid \text{ et indépendant de } u_i.$$
où $g : \ ]0,1[ \ \rightarrow \ ]-\infty, +\infty[$ est une fonction de lien, $\beta_j=(\beta_{j1},\ldots,\beta_{jp})'$ et $\beta_{j0}$ sont les coefficients de régression correspondants aux variables bioclimatiques et l'intercept pour l'espèce $j$ qui est supposé être un effet fixe, $\alpha_i$ représente l'effet aléatoire du site $i$, et $u_i=(u_{i1},\ldots,u_{iJ})$ est un effet aléatoire multivarié corrélé dont la matrice de variance covariance $\Sigma$ controle la corrélation entre les espèces et est supposée être complètement non structurée.    
Cette dernière partie du modèle est problématique lorsque le nombre d'espèces $J$ est important car le nombre de paramètres dans $\Sigma$ augmente quadratiquement avec $J$.

## Modèle à variable latente (LVM)

D'autre part en posant $u_{ij} = W_i\lambda_j$, avec $W_i=(W_{i1},\ldots,W_{iq})$ les $q$ variables latentes (ou "variables latentes") considérés et $\lambda_j=(\lambda_{j1},\ldots, \lambda_{jq})'$ les coefficients associés, on obtient le modèle à variables latentes **(LVM)** suivant : 
$$g(\theta_{ij}) =\alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$$
$$y_{ij} \ | \ W_i, \alpha_i \sim \mathcal{B}ernoulli(\theta_{ij}),$$
$$W_i \sim \mathcal{N}(0,I_q) \ iid $$
$$\alpha_i \sim \mathcal{N}(0,V_{\alpha}) \ iid \text{ et indépendant de } W_i$$ 

Ce qui revient à un cas particulier de GLMM multivarié auquel on impose la contrainte $\Sigma = \Lambda\Lambda'$ avec 
$$\Lambda := \begin{pmatrix}
\lambda_{11} & \ldots & \lambda_{1q} \\
\vdots & \vdots & \vdots \\
\lambda_{J1} & \ldots & \lambda_{Jq}
\end{pmatrix}$$

On préferera ce dernier modèle, en effet il comporte potentiellement beaucoup moins de paramètres que le GLMM précédent car $\Lambda$ a autant de colonne qu’il y a de variables latentes ($q$) tandis que $\Sigma$ présente autant de colonnes de paramètres qu’il y a d’espèces ($J$).

On peut choisir de modéliser l'abondance absolue plutôt que l'abondance relative en supprimant les effets sites aléatoires  $\alpha_i$ du modèle. 

# Méthodes d’inférence bayesienne selon la fonction de lien choisie 

## Principe d’un échantillonneur de Gibbs

Dans le cadre bayésien, l’algorithme de Gibbs permet d’obtenir une réalisation du paramètre $\theta=(\theta_),\ldots,\theta_m)$ suivant la loi *a posteriori* $\uppi(\theta \ | \ x)$ dès que l’on est capable d’exprimer les lois conditionnelles : $\uppi(\theta_i \ | \ \theta_1,\dots,\theta_{i-1},\theta_{i+1},\ldots,\theta_m, x)$ pour $i =1,\ldots,m$.  

\vspace{0.2cm}

L’**échantillonnage de Gibbs** consiste à : 
\begin{itemize}
\item \textbf{Initialisation} : choix arbitraire de $\theta^{(0)}= (\theta_1^{(0)},\dots,\theta_m^{(0)})$.
\vspace{0.2cm}
\item \textbf{Itération $t$} : Générer $\theta^{(t)}$ de la manière suivante :
\vspace{0.2cm}
  \begin{itemize}
  \item[$\bullet$] $\theta_1^{(t)} \sim \uppi\left(\theta_1 \ | \theta_2^{(t-1)},\dots, \theta_m^{(t-1)}, x \right)$
\vspace{0.1cm}
  \item[$\bullet$] $\theta_2^{(t)} \sim \uppi\left((\theta_2 \ | \ (\theta_1^{(t)}, \theta_3^{(t-1)},\ldots,\theta_m^{(t-1)},x\right)$
  \item[$\bullet$] $\theta_m^{(t)} \sim \uppi\left(\theta_m \ | \ \theta_1^{(t)}, \ldots, \theta_{m-1}^{(t)},x\right)$
\end{itemize}
\end{itemize}

Les itérations successives de cet algorithme génèrent les états d’une chaîne de
Markov $\{\theta^{(t)}, t > 0\}$ à valeurs dans $\mathbb{R}^{m}$, on montre que cette chaîne admet une mesure invariante qui est la *loi a posteriori*.  
Pour un nombre d’itérations suffisamment grand, le vecteur $\theta$ obtenu peut donc être considéré comme étant une réalisation de la loi *a posteriori* jointe $\uppi(\theta \ | \ x)$. 
\vspace{0.2cm} 

Par conséquent l'implémentation d'un échantillonneur de Gibbs nécessite la connaissance des ditributions *a posteriori* de chacun des paramètres conditionnellement aux autres paramètres du modèle, qui se déduisent des formules de priors conjugués dans le cas du modèle probit mais ne sont pas explicitement exprimables dans le cas où on utilise une fonction de lien logit.

## Modèle probit : échantillonneur de Gibbs et priors conjugués 

D’une part, on utilise un fonction de lien $\mathrm{probit} : p \rightarrow \Phi^{-1}(p)$ où $\Phi$ correspond à la fonction de répartition d’une loi normale centrée réduite.  

### Définition du modèle probit

D’après l’article @Albert1993, une modélisation possible est de supposer l’existence d’une variable latente sous-jacente liée à notre variable binaire observée en utilisant la proposition suivante :

\begin{prop}[Modèle probit par l'intermédiaire d'une variable latente]  \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad  \qquad \qquad \qquad  \qquad \qquad \qquad \qquad   

Si $Z_{ij} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j + \epsilon_{ij}, \ \forall i,j \text{ avec }  \epsilon_{ij} \sim \mathcal{N}(0,1) \ iid $ et tel que :
$$y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$$
Alors on a $y_{ij} \ |\ Z_{ij} \sim \mathcal{B}ernoulli(\theta_{ij})$ avec
$\mathrm{probit(\theta_{ij})} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j$.
\end{prop}
\begin{dem}   
$$\begin{aligned}
\mathbb{P}(y_{ij}=1) & = \mathbb{P}(Z_{ij} > 0)\\
& = \mathbb{P}(\alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j + \epsilon_{ij} > 0)\\
& = \mathbb{P}(\epsilon_{ij} > - (\alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \ ) \\
& = \mathbb{P}(\epsilon_{ij} \leq \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
& = \Phi( \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
\end{aligned}$$
De la même façon on a :   
$$\begin{aligned}
\mathbb{P}(y_{ij}=0) & = \mathbb{P}(Z_{ij} \leq 0)\\
& = 1 - \Phi( \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j) \\
\end{aligned}$$
\end{dem}
On définit le modèle probit à l’aide d’une variable latente afin d’être en mesure d’utiliser les propriétés des priors conjugués pour échantillonner les paramètres du modèle selon leurs distributions conditionnelles *a posteriori*. 

### Priors utilisés 

Afin d’utiliser une méthode d’inférence bayesienne on détermine une distribution *a priori* pour chacun des paramètres du modèle :
$$\begin{array}{lll}
V_{\alpha} & \sim & \mathcal {IG}(\text{shape}=0.5, \text{rate}=0.005) \text{ avec } \mathrm{rate}=\frac{1}{\mathrm{scale}}, \\
\beta_{jk} & \sim & \mathcal{N}(0,10^6)  \text{ pour } j=1,\ldots,J \text{ et } k=1,\ldots,p, \\
\lambda_{jl} & \sim & \begin{cases}
\mathcal{N}(0,10) & \text{si } l < j \\
\mathcal{N}(0,10) \text{ tronquée à gauche par } 0 & \text{si } l=j \\
P \text{ tel que } \mathbb{P}(\lambda_{jl} = 0)=1  & \text{si } l>j
\end{cases} \\
\quad & \quad & \text{ pour } j=1,\ldots,J \text{ et } l=1,\ldots,q.
\end{array}$$
En effet pour assurer l’identifiabilité du modèle les valeurs de $\Lambda$ sont contraintes à des valeurs strictements positives sur la diagonale et nulles au dessus de celle-ci, $\Lambda$ est ainsi supposée être triangulaire inférieure d’après l’article @Warton2015. 

La fonction *boral()* du package du même nom, permettant d'ajuster différents modèles utilise ces distributions *a priori* pour le modèle qui nous intéresse. Dans l'article @Warton2015 l'ajustement de modèles joints de distributions des espèces est réalisé à l'aide de boral qui fonctionne avec JAGS (Just Another Gibbs Sampler) un programme de simulation à partir de modèles hiérarchiques bayésiens utilisant des méthodes MCMC, implémenté en C++. Cependant la fonction *jSDM_probit_block()* du package jSDM que j'ai implémentée utilise une distribution *a priori* jointe pour les effets espèces fixes de la manière qui suit.

### Propositions sur les priors conjugués  

**Effets espèces fixes**:  

On se ramène à un modèle de la forme $Z^* = X\beta + \epsilon$, en posant $Z^*_{ij} = Z_{ij}  - \alpha_i = \beta_{j0} + X_i\beta_j+ W_i\lambda_j+\epsilon_{ij}$, afin d'estimer simultanément les $\beta_j$ et $\lambda_j$ pour chacune des espèces $j$,   ce qui revient en écriture matricielle à : 
$$\begin{aligned} 
Z^*_{j} = &\begin{pmatrix} 
Z^*_{1j} \\
\vdots \\
Z^*_{Ij}
\end{pmatrix} =  \underbrace{
\begin{pmatrix}
 1 & X_{11} & \ldots & X_{1p} & W_{11} & \ldots & W_{1q}\\
 \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
 1 & X_{I1} & \ldots & X_{Ip} & W_{I1} & \ldots & W_{Iq}\\
\end{pmatrix}}_{D}
\underbrace{
\begin{pmatrix}
\beta_{j0} \\
\beta_{j1} \\
\small{\vdots} \\
\beta_{jp} \\
\lambda_{j1} \\
\small{\vdots} \\
\lambda_{jq} 
\end{pmatrix}}_{P_j}
+ \begin{pmatrix} 
\epsilon_{1j} \\
\vdots \\
\epsilon_{Ij}
\end{pmatrix} \\
& =  DP_j + \epsilon_j \quad \text{ avec } \epsilon_j \sim \mathcal{N}_I(0_{\mathbb{R}^I},I_I).
\end{aligned}$$
On suppose que $P_j \sim \mathcal{N}_{p+q+1}(m,V)$ avec $m=0_{\mathbb{R}^{p+q+1}}$ et $V=diag(\underbrace{10^6,\ldots,10^6}_{\times p+1},\underbrace{10,\ldots,10}_{\times q})$, par exemple.  
Bien que cette distribution *a priori* ne prenne pas en compte les contraintes sur $\Lambda$, elle permet l'échantillonnage selon une loi normale multivariée des effets espèce fixes. On imposera les contraintes aux $\lambda_{jl}$ concernés après les avoir simulés. 

On applique la proposition suivante : 

\begin{prop}
$$\begin{cases} 
Y \ | \ \beta \sim \mathcal{N}_n ( X\beta, I_n) \\
\beta  \sim \mathcal{N}_p (m,V)
\end{cases}
\Rightarrow \begin{cases}
\beta|Y \sim \mathcal{N}_p (m^*,V^*) \text{ avec }  \\
m^* = (V^{-1} + X'X)^{-1}(V^{-1}m + X'Y)\\
V^*=(V^{-1} + X'X)^{-1} 
\end{cases}$$.
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\beta \ | \ Y) & \propto  p(Y \ | \ \beta) \ p(\beta) \\
& \propto  \frac{1}{(2\pi)^{\frac{n}{2}}}\exp\left(-\frac{1}{2}(Y-X\beta)'(Y-X\beta)\right)\frac{1}{(2\pi)^{\frac{p}{2}}|V|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}(\beta-m)'V^{-1}(\beta-m)\right) \\
& \propto \exp\left(-\frac{1}{2}\left((\beta-m)'V^{-1}(\beta-m) + (Y-X\beta)'(Y-X\beta)\right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'V^{-1}\beta + m'V^{-1}m - m'V^{-1}\beta -\beta'V^{-1}m + Y'Y + \beta'X'X\beta - Y'X\beta - \beta'X'Y\right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (Y'X + m'V^{-1})\beta + m'V^{-1}m + Y'Y \right)\right) \\
& \propto \exp\left(-\frac{1}{2}\left(\beta'(V^{-1}+X'X)\beta -\beta'(V^{-1}m + X'Y) - (X'Y + V^{-1}m)'\beta + m'V^{-1}m + Y'Y \right)\right) \\
& \propto \exp(-\frac{1}{2}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)'(V^{-1}+X'X)\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\\
& \quad -(V^{-1}m + X'Y)'(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y) +m'V^{-1}m + Y'Y)\\
& \propto \exp\left(-\frac{1}{2}\left(\beta - \underbrace{(V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)}_{m^*}\right)'\underbrace{(V^{-1}+X'X)}_{{V^*}^{-1}}\left(\beta - (V^{-1}+X'X)^{-1}(V^{-1}m + X'Y)\right)\right)
\end{aligned}$$
\end{dem}
On obtient : 
$$\begin{cases} 
Z^*_j \ | \ P_j \sim \mathcal{N}_{I} ( DP_j, I_{I}) \\
P_j \sim \mathcal{N}_{p+q+1}(m,V)
\end{cases}
\Rightarrow \begin{cases}
P_j \ | \ Z^*_j  \sim \mathcal{N}_{p+q+1} (m^*,V^*) \text{ avec }  \\
m^* = (V^{-1} + D'D)^{-1}(V^{-1}m + D'Z^*_j)\\
V^*=(V^{-1} + D'D)^{-1} 
\end{cases}$$.

**Variables latentes (prédicteurs non mesurés) : **

De la même façon, on pose : $Z^\star_{ij} = Z_{ij} - \alpha_i - \beta_{j0} - X_i\beta_j = W_i\lambda_j + \epsilon_{ij}$, afin d’estimer $W_i$ pour chaque site $i$.  
En appliquant la proposition précédente, on obtient :

$$\begin{cases} 
Z^*_i := (Z^*_{i1},\ldots,Z^*_{iJ})' \ | \ W_i \sim \mathcal{N}_{J} ( \Lambda W_i', I_{J}) \\
W_i' \sim \mathcal{N}_{q}(0_{\mathbb{R}^{q}},I_q)
\end{cases}
\Rightarrow \begin{cases}
W_i' \ | \ Z^*_i \sim \mathcal{N}_{q} (m^*,V^*) \text{ avec }  \\
m^* = (I_q + \Lambda'\Lambda)^{-1}(\Lambda'Z^*_i)\\
V^* = (I_q + \Lambda'\Lambda)^{-1} 
\end{cases}$$.

**Effets sites aléatoires et variance associée : **   

En ce qui concerne les effets sites aléatoires  $(\alpha_i)_{i=1,\dots,I}$, on pose $Z^*_{ij} = Z_{ij} - D_iP_j = \alpha_i + \epsilon_{ij}$, avec $D_i =(1,X_{i1},\ldots,X_{ip},W_{i1},\ldots,W_{iq})$. \smallskip   
On a ainsi $Z^*_{ij} \ | \ \alpha_i \ \sim \mathcal{N}(\alpha_i,1)$ *iid* pour $j=1,\ldots,J$, puis on applique la proposition suivante : 
\begin{prop}
$$\begin{cases} 
x_i \ | \ \theta \sim \mathcal{N}(\theta, \ \sigma^2) \ iid \text{ pour } i=1,\ldots,n\\
\theta \sim \mathcal{N}(\mu_0,{\tau_0}^2) \\
\sigma^2 \text{ connu}
\end{cases}
\Rightarrow
\begin{cases} 
\theta | \ x_1, \ldots,x_n \sim \mathcal{N}(\mu_1,{\tau_1}^2) \text{ avec } \\
\mu_1 = \dfrac{{\tau_0}^{-2}\mu_0 + \sigma^{-2}\sum_{i=1}^nx_i}{{\tau_0}^{-2}+n\sigma^{-2}} \\
{\tau_1}^{-2} = {\tau_0}^{-2}+n\sigma^{-2}
\end{cases}$$. 
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\theta \ | \ x_1,\ldots,x_n) & \propto p(\theta) p(x_1,\ldots,x_n \ | \ \theta) \\
& \propto  \frac{1}{(2\pi{\tau_0}^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2\right) \prod\limits_{i=1}^n\frac{1}{(2\pi\sigma^2)^{\frac{1}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x_i-\theta)^2\right) \\
& \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta-\mu_0)^2-\frac{1}{2\sigma^2}\sum\limits_{i=1}^n(x_i-\theta)^2\right) \\
& \propto \exp\left(-\frac{1}{2{\tau_0}^2}(\theta^2-2\mu_0\theta)-\frac{1}{2\sigma^2}\sum\limits_{i=1}^n(\theta^2-2\theta x_i)\right)\\
& \propto \exp\left(-\frac{1}{2}\left(\theta^2 ({\tau_0}^{-2}+n\sigma^{-2})-2\mu_0\theta{\tau_0}^{-2}-2\theta\sigma^{-2}\sum\limits_{i=1}^n x_i\right)\right)\\
& \propto \exp\left(-\frac{1}{2({\tau_0}^{-2}+n\sigma^{-2})^{-1}}\left(\theta -\frac{\mu_0{\tau_0}^{-2}+ \sigma^{-2}\sum\limits_{i=1}^n x_i}{{\tau_0}^{-2}+n\sigma^{-2}}\right)^2\right)\\
\end{aligned}$$
\end{dem}
On obtient ainsi : 
$$\begin{cases} 
Z^*_{ij} \ | \ \alpha_i \sim \mathcal{N}(\alpha_i, \ 1) \text{, iid } \forall j=1,\ldots,J\\
\alpha_i \sim \mathcal{N}(0,V_{\alpha}) \\
\end{cases}
\Rightarrow
\begin{cases} 
\alpha_i | \ Z^*_{i1}, \ldots, Z^*_{iJ} \sim \mathcal{N}(\mu_1,{\tau_1}^2) \text{ avec } \\
\mu_1 = \dfrac{ \sum_{j=1}^J Z^*_{ij}}{V_{\alpha}^{-1}+ J} \text{ et } {\tau_1}^{-2} = V_{\alpha}^{-1}+ J.
\end{cases}$$
Finalement pour estimer $V_{\alpha}$, la variance des effets sites aléatoires $(\alpha_i)_{i=1,\dots,I}$, on utilise la proposition suivante :
\begin{prop}
Si $$\begin{cases} 
x \ | \ \sigma^2 \sim \mathcal{N}_n (\theta, \ \sigma^2I_n) \\
\sigma^2   \sim \mathcal{IG} (a,b) \\
\theta \text{ connu}
\end{cases} \Rightarrow 
\begin{cases}
\sigma^2|x \sim \mathcal{IG}(a',b') \text{ avec } \\
a' = a + \frac{n}{2} \text { et } b' = \frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2 + b. 
\end{cases}$$
\end{prop}
\begin{dem}
$$\begin{aligned}
p(\sigma^2 \ | \ x) & \propto  p(x \ | \ \sigma^2) \ p(\sigma^2) \\
& \propto  \frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}\exp\left(-\frac{1}{2\sigma^2}(x-\theta)'(x-\theta)\right)\frac{b^a}{\Gamma(a)}{(\sigma^2)}^{-(a+1)}\exp\left(-\frac{b}{\sigma^2}\right) \\
& \propto {(\sigma^2)}^{-\left(\frac{n}{2}+a+1\right)}\exp\left(-\frac{1}{\sigma^2}\left(b+\frac{1}{2}\sum\limits_{i=1}^n(x_i-\theta)^2\right)\right)
\end{aligned}$$
\end{dem}
On a donc : $$\begin{cases} 
(\alpha_1,\ldots,\alpha_I)' \ | \ V_{\alpha} \sim \mathcal{N}_n (0_{\mathbb{R}^I}, V_\alpha I_n) \\
V_\alpha \sim \mathcal{IG} (a,b) \\
\end{cases} \Rightarrow 
\begin{cases}
V_\alpha \ | \ \alpha_1,\ldots,\alpha_I \sim \mathcal{IG}(a',b') \text{ avec } \\
a' = a + \frac{I}{2} \text{ et } b' = b + \frac{1}{2}\sum\limits_{i=1}^I \alpha_i^2. 
\end{cases}$$

\newpage
### Echantillonneur de Gibbs et priors conjugués
L’algorithme utilisé pour estimer les paramètres du modèle logit est donc le suivant :
\begin{itemize}
\item Définir les constantes $N_{Gibbs}$, $N_{burn}$, $N_{thin}$ telles que $N_{Gibbs}$ correspond au nombre d’itérations effectuées par l’échantillonneur de Gibbs,  $N_{burn}$ au nombre d’itérations nécessaires pour le burn-in ou temps de chauffe et $N_{samp} = \dfrac{N_{Gibbs}-N_{burn}}{N_{thin}}$ au nombre de valeurs estimées retenues pour chaque paramètre. En effet on enregistre les paramètres estimés à certaines itérations, afin d’obtenir un échantillon de $N_{samp}$ valeurs distribuées selon la distribution \it{a posteriori} pour chacun des paramètres.
\vspace{0.2cm}
\item Initialiser tous les paramètres à $0$ par exemple, excepté les valeurs diagonales de $\Lambda$ initialisées à $1$ et $V_{\alpha}^{(0)}=1$.
\vspace{0.2cm}
\item Gibbs sampler : à chaque itération $t$ pour $t=1,\ldots,N_{Gibbs}$ on répète chacune de ces étapes :
  \begin{itemize}
  \item[$\bullet$] Génerer la \textbf{variable latente} $Z^{(t)}=\left(Z_{ij}^{(t)}\right)_{i=1,\ldots,I}^{j=1,\ldots,J}$ telle que
$$Z_{ij}^{(t)} \sim  \begin{cases} 
\mathcal{N}\left(\alpha_i^{(t−1)} + \beta_{j0}^{(t−1)} + X_i\beta_j{(t−1)} + W_i^{(t−1)}\lambda_j^{(t−1)}, \ 1 \right) \text{ tronquée à droite par } 0 & \text{si } y_{ij } =0 \\ 
\mathcal{N}\left(\alpha_i^{(t−1)} + \beta_{j0}^{(t−1)} + X_i\beta_j{(t−1)} + W_i^{(t−1)}\lambda_j^{(t−1)}, \ 1 \right) \text{ tronquée à gauche par } 0 &        \text{si } y_{ij} =1
\end{cases}$$
, la variable latente est ainsi initialisée à la première itération en la générant selon ces lois normales centrées.
\vspace{0.1cm}
  \item[$\bullet$] Générer les \textbf{effets espèces fixes} $P_j^{(t)}=(\beta_{j0}^{(t)},\beta_{j1}^{(t)} \ldots, \beta_{jp}^{(t)},\lambda_{j1}^{(t)},\ldots, \lambda_{jq}^{(t)})'$ pour $j=1,\ldots,J$ selon : 
$$P_j^{(t)} \ | \ Z^{(t)}, W_1^{(t-1)}, \alpha_1^{(t-1)}, \ldots, W_I^{(t−1)}, \alpha_I^{(t-1)} \sim \mathcal{N}_{p+q+1}(m^\star,V^\star) \text{, avec }$$
$$m^\star = (V^{-1} + {D^{(t)}}'D^{(t)})^{-1}(V^{-1}m + {D^{(t)}}'Z^\star_j) \text{ et } V^\star = \left(V^{-1}+{D^{(t)}}'D^{(t)}\right)^{-1},$$
$$\text{où } Z_j^\star =(Z_{1j}^\star,\ldots,Z_{Ij}^\star)' \text{ tel que } Z^\star_{ij} = Z_{ij}^{(t)}-\alpha_i^{(t-1)}.$$
Afin de contraindre les valeurs diagonales de $\Lambda =\left(\lambda_{jl}\right)_{j=1,\ldots,J}^{l=1,\ldots,q}$ à des valeurs positives et de rendre la
matrice triangulaire inférieure, on modifie les valeurs des $P^{(t)}$ simulées aléatoirement selon les conditions suivantes :
$$P_{jp+1+l}^{(t)} = \lambda_{jl}^{(t)} \leftarrow \begin{cases}
0 & \text{si } l>j \\
\lambda_{jl}^{(t-1)} & \text{si } l=j \text{ et } \lambda_{jl}^{(t)} < 0.
\end{cases}$$ 
On pose $P^{(t)}=\left( P_1^{(t)} | \ldots | P_J^{(t)} \right)$.  
\vspace{0.1cm}

\item[$\bullet$] Générer les \textbf{variables latentes} (ou prédicteurs non mesurés) $W_i^{(t)}$ pour $i=1,\ldots,I$ selon : $$W_i^{(t)} \ | \ Z^{(t)}, P^{(t)},  \alpha_i^{(t-1)} \sim \mathcal{N}_{q} \left((I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}({\Lambda^{(t)}}'Z_i^{\star \star}),(I_q + {\Lambda^{(t)}}'\Lambda^{(t)})^{-1}\right),$$
$$\text{où } Z_i^{\star \star} =(Z_{i1}^{\star \star},\ldots,Z_{iJ}^{\star \star}) \text{ tel que } Z_{ij}^{\star \star } = Z_{ij}^{(t)}-\alpha_i^{(t-1)} − \beta_{j0}^{(t)} - X_i\beta_j^{(t)}.$$ On pose $D_i^{(t)} = \left(1,X_{i1},\ldots,X_{ip},W_{i1}^{(t)}, \ldots, W_{iq}^{(t)} \right)$.

  \item[$\bullet$] Générer les \textbf{effets sites aléatoires} $\alpha_i^{(t)}$ pour $i=1,\ldots,I$ selon :
$$ \alpha_i | \ Z^{(t)}, P^{(t)},W_i^{(t)} \sim \mathcal{N}\left(\dfrac{ \sum_{j=1}^J Z_{ij}^{(t)} - D_i^{(t)}P_j^{(t)}}{{V_{\alpha}^{(t-1)}}^{-1} + J} , \left( \frac{1}{V_{\alpha}^{(t-1)}}+ J \right)^{-1}  \right)$$

  \item[$\bullet$] Générer la \textbf{variance des effets sites aléatoires} $V_\alpha^{(t)}$ selon : $$V_\alpha^{(t)} \ | \ \alpha_1^{(t)},\ldots,\alpha_I^{(t)} \sim \mathcal{IG}\left( \text{shape}=0.5 + \frac{I}{2}, \text{rate}=0.005 + \frac{1}{2}\sum\limits_{i=1}^I \left(\alpha_i^{(t)}\right)^2\right)$$
  \end{itemize}
\end{itemize}

\newpage 
## Modèle logit : échantillonneur de Gibbs et algorithme de Metropolis adaptatif  

D'autre part on considère une fonction de lien $\mathrm{logit}: p \rightarrow\ln\left(\frac{p}{1-p}\right)=\mathrm{F}^{-1}(p)$, avec $\mathrm{F}:x\rightarrow \frac{1}{1+e^{-x}}$ la fonction de répartition appelée sigmoïde d’une loi logistique standard. 
 
### Définition du modèle logit
De la même façon que pour le modèle probit, d’après @Givord2016 on peut définir le modèle logit par l’intermediaire d’une variable latente : $Z_{ij}= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j + \epsilon_{ij}$ pour $i=1,\ldots,I$ et $j=1,\ldots,J$, avec $\epsilon_{ij} \sim \mathrm{logistique}(0,1)$ *iid* et telle que : 
$$y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$$ 
Cependant dans ce cas les distributions *a priori* de la variable latente et des paramètres n’étant pas conjuguées, on n’est pas en mesure d’utiliser les propriétés des priors conjugués donc la modélisation à l’aide d’une variable latente ne présente pas d’intérêt.    

Dans ce cas on suppose que $$y_{ij} \ | \theta_{ij} \sim \mathcal{B}(n_i,\theta_{ij})$$, avec
$\mathrm{probit(\theta_{ij})} = \alpha_i + \beta_{j0}+X_i\beta_j+ W_i\lambda_j$ et $n_i$ le nombre de visites du site $i$.    

Par conséquent on échantillonnera les paramètres de ce modèle selon une estimation de leurs distributions conditionnelles *a posteriori* à l’aide d’un algorithme de Metropolis adaptatif.  

### Priors utilisés 
On détermine une distribution *a priori* pour chacun des paramètres du modèle :  

$$\begin{array}{lll}
V_{\alpha} & \sim & \mathcal {IG}(\text{shape}=0.5, \text{rate}=0.005) \text{ avec } \mathrm{rate}=\frac{1}{\mathrm{scale}}, \\
\beta_{jk} & \sim & \mathcal{N}(0,10^6)  \text{ pour } j=1,\ldots,J \text{ et } k=1,\ldots,p, \\
\lambda_{jl} & \sim & \begin{cases}
\mathcal{N}(0,10) & \text{si } l < j \\
\mathcal{U}(0,10) &  \text{si } l=j \\
P \text{ tel que } \mathbb{P}(\lambda_{jl} = 0)=1  & \text{si } l>j
\end{cases} \\
\quad &  \quad & \text{ pour } j=1,\ldots,J \text{ et } l=1,\ldots,q.
\end{array}$$

### Principe d'un algorithme de Metropolis adaptatif 

Cet algorithme appartient aux méthode MCMC et permet d’obtenir une réalisation du paramètre $\theta=(\theta_),\ldots,\theta_m)$ selon leurs distributions conditionnelles *a posterirori* $\uppi(\theta_i \ | \ \theta_1,\dots,\theta_{i-1},\theta_{i+1},\ldots,\theta_m, x)$, pour $i =1,\ldots,m$ connues à une constante multiplicative près.  
On le qualifie d'adaptatif car la variance de la densité instrumentale conditionnelle utilisée est adaptée en fonction du nombre d'acceptation lors des dernières itérations. 

\begin{itemize}
\item \textbf{Initialisation} : $\theta^{(0)}= (\theta_1^{(0)},\ldots,\theta_m^{(0)})$ fixés arbitrairement, les nombres d'acceptation $(n^A_{i})_{i=1,\ldots,m}$ sont intialisés à $0$ et les variances $(\sigma^2_i)_{i=1,\ldots,m}$ sont intialisées à $1$.
\item \textbf{Itération t} : pour $i=1,\ldots,m$
  \begin{itemize}
  
  \item[$\bullet$] Générer $\theta_i^\star \sim q(\theta_i^{(t-1)},.)$, avec une densité instrumentale conditionnelle $q(\theta_i^{(t-1)},\theta_i^\star)$ symétrique, on choisira une loi $\mathcal{N}(\theta_i^{(t-1)},{\sigma^2_{i}})$ par exemple.
  
  \item[$\bullet$] Calculer la probabilité d'acceptation : 
  $$\gamma=  min\left(1,\dfrac{\uppi\left(\theta_i^\star \ | \ \theta_1^{(t-1)},\dots,\theta_{i-1}^{(t-1)},\theta_{i+1}^{(t-1)},\ldots,\theta_m^{(t-1)}, x \right)}{\uppi\left(\theta_i^{(t-1)} \ | \ \theta_1^{(t-1)},\dots,\theta_{i-1}^{ (t-1)},\theta_{i+1}^{(t-1)},\ldots,\theta_m^{(t-1)},x\right)}\right)$$.
  
  \item[$\bullet$] Retenir $$\theta_i^{(t)} =  
  \begin{cases} 
  \theta_i^\star & \text{ avec probabilité } \gamma \\
  &\text{ si on est dans ce cas le nombre d'acceptation devient : } n^A_{i} \leftarrow n^A_{i} +1 \\
  \theta_i^{(t-1)} & \text{ avec probabilité } 1-\gamma. \\
  \end{cases}$$
  \end{itemize}
  
\item \textbf{Durant le burn-in}, toutes les $\mathrm{DIV}$ itérations, avec 
$$\mathrm{DIV} =  \begin{cases} 
100 & \text{ si } N_{Gibbs} \geq 1000 \\
\dfrac{N_{Gibbs}}{10}& \text{sinon }  \\
\end{cases}$$
, où $N_{Gibbs}$ est le nombre total d'itérations effectuées.   

On modifie les variances en fonction des nombres d'acceptation de la manière suivante pour $i=1,\ldots,m$ : 

\begin{itemize}
  \item[$\bullet$] On calcule le taux d'acceptation : $r^A_{i} = \dfrac{ n^A_i}{\mathrm{DIV}}$.
  \item[$\bullet$] On adapte les variances selon le taux d'acceptation et une constante fixée $R_{opt}$ : $$\sigma_i \leftarrow \begin{cases}  
\sigma_i\left(2-\dfrac{1-r^A_i}{1-R_{opt}}\right) & \text{ si } r^A_{i} \geq R_{opt} \\ \\
\dfrac{\sigma_i}{2-\dfrac{1-r^A_i}{1-R_{opt}}} & \text{ sinon }
\end{cases}$$  
  \item[$\bullet$] On réinitialise les nombres d'acceptation : $n^A_i \leftarrow 0$.  
  \end{itemize} 
\item Toutes les $\dfrac{N_{Gibbs}}{10}$ itérations, on calcule et affiche les taux d'acceptation moyen $m^A = \dfrac{1}{m}\sum\limits_{i=1,\ldots,m}r^A_i$.
\end{itemize}

### Echantillonneur de Gibbs et algorithme de Metropolis adaptatif

On utilise un algorithme de Metropolis adapatatif pour échantillonner les paramètres du modèle selon leurs distributions conditionnelles *a posteriori* estimées à une constante multiplicative près.

Dans un premier temps on définit la fonction $f$ permettant de calculer la vraisemblance du modèle en fonction des paramètres estimés :
$$ f : \lambda_j,\beta_{j0},\beta_j,\alpha_i, W_i, X_i, y_{ij},n_i \rightarrow  f(\lambda_j,\beta_{j0},\beta_j,\alpha_i, W_i, X_i, y_{ij},n_i)=\mathrm{L}(\theta_{ij})$$
\begin{itemize}
\item Calcul $\mathrm{logit}(\theta_{ij})= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$.
\item Calcul $\theta_{ij}= \dfrac{1}{1+\exp\left(-\mathrm{logit}(\theta_{ij})\right)}$.
\item Renvoi $\mathrm{L}(\theta_{ij})= p(y_{ij} \ | \ \theta_{ij},n_i)= \dbinom{n_i}{y_{ij}}(\theta_{ij})^{y_{ij}}(1-\theta_{ij})^{n_i-y_{ij}}$.
\end{itemize}
On répète ces étapes pour $i=1,\ldots,I$ et $j=1,\ldots,J$, et on pose $\theta = \left(\theta{ij}\right)_{i=1,\ldots I}^{j= 1,\ldots,J}$.  

On peut ainsi calculer la vraisemblance du modèle : $\mathrm{L}(\theta)= \prod\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\mathrm{L}(\theta_{ij})$.  

D’après la formules de Bayes on a $$\mathrm{p}(\theta \ |  \ Y) \propto \uppi(\theta) \mathrm{L}(\theta).$$
On utilise donc les relations suivantes pour approcher les densités conditionnelles *a posteriori* de chacun des paramètres avec $\uppi(.)$ les densités correspondants à leurs lois *a priori*.

$$\begin{aligned}
& p(\beta_{jk} \ |  \ \beta_{j0},\beta_{j1},\ldots,\beta_{jk-1},\beta_{jk+1},\ldots,\beta_{jp}, \lambda_j,\alpha_1,\ldots,\alpha_I, W_1,\ldots,W_I,Y) \propto \uppi(\beta_{jk})\prod\limits_{1\leq i\leq I}  \mathrm{L}(\theta_{ij})\\
&p(\lambda_{jl} \ |  \ \lambda_{j1},\ldots,\lambda_{jl-1},\lambda_{jl+1},\ldots,\lambda_{jq}, \beta_j,\beta_{j0},\alpha_1,\ldots,\alpha_I, W_1,\ldots,W_I,Y) \propto  \uppi(\lambda_{jl}) \prod\limits_{1\leq i \leq I}\mathrm{L}(\theta_{ij})\\
&p(W_{il} \ |  \ W_{i1},\ldots,W_{il-1},W_{il+1},\ldots,W_{iq},\alpha_i,\beta_{10},\ldots,\beta_{J0},\beta_1,\ldots,\beta_J,\lambda_1,\ldots, \lambda_J,Y) \propto \uppi(W_{il}) \prod\limits_{1\leq j\leq J}\mathrm{L}(\theta_{ij})\\
&p(\alpha_i \ |  \ W_i,\beta_{10},\ldots,\beta_{J0},\beta_1,\ldots,\beta_J,\lambda_1,\ldots, \lambda_j,V_{\alpha},Y) \propto \uppi(\alpha_i \ | \ V_{\alpha}) \prod\limits_{1\leq j\leq J}\mathrm{L}(\theta_{ij})\\
& \text{, pour $i=1,\ldots,I$, $j=1,\ldots,J$, $k=1,\ldots,p$ et $l=1,\ldots,q$. 
}
\end{aligned}$$

\newpage
L’algorithme utilisé pour estimer les paramètres du modèle logit est donc le suivant :

\begin{itemize}
\item Définition des constantes $N_{Gibbs}$, $N_{burn}$, $N_{thin}$ et $R_{opt}$ tels que  $N_{Gibbs}$ correspond au nombre d'itérations effectuées par l'algorithme,  $N_{burn}$ au nombre d'itérations nécessaires pour le burn-in ou temps de chauffe,   
$N_{samp}= \dfrac{N_{Gibbs}-N_{burn}}{N_{thin}}$ correspondant au nombre de valeurs estimées retenues pour chaque paramètre. En effet on enregistre les paramètres estimés à certaines itérations afin d'obtenir $N_{samp}$ valeurs, nous permettant de représenter une distribution \it{a posteriori} pour chacun des paramètres.  

On fixe $R_{opt}$ le ratio d'acceptation optimal utilisé dans les algorithmes de Metropolis adaptatifs implémentés pour chacun des paramètres du modèle. 

\item Initialiser tous les paramètres à $0$ par exemple, excepté les valeurs diagonales de $\Lambda$ initialisées à $1$ et $V_{\alpha}^{(0)}=1$. Le nombre d'acceptation de chaque paramètre est intialisé à $0$ et les variances de leur densités instrumententales conditionnelles prennent la valeur $1$.
\item Gibbs sampler : à chaque itération $t$ pour $t=1,\ldots,N_{Gibbs}$ on répète chacune de ces étapes :
  \begin{itemize}
\vspace{0.1cm}
\item[$\bullet$] Générer les \textbf{effets sites aléatoires} $\alpha_i^{(t)}$ pour $i=1,\ldots,I$ selon un algorithme de Metropolis adaptatif simulant $\alpha_i^\star \sim \mathcal{N}(\alpha_i^{(t-1)},\sigma_{\alpha_i}^2)$ puis calculant le taux d'acceptation de la manière suivante :  
$$\gamma =min\left(1, \ \dfrac{\uppi\left(\alpha_i^\star \ | \ V_{\alpha}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(\alpha_i^\star, W_i^{(t-1)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}{\uppi\left(\alpha_i^{(t-1)} \ | \ V_{\alpha}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(\alpha_i^{(t-1)}, W_i^{(t-1)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}\right).$$

\item[$\bullet$] Générer la \textbf{variance des effets sites aléatoires} $V_\alpha^{(t)}$ selon : $$V_\alpha^{(t)} \ | \ \alpha_1^{(t)},\ldots,\alpha_I^{(t)} \sim \mathcal{IG}\left( \text{shape}=0.5 + \frac{I}{2}, \text{rate}=0.005 + \frac{1}{2}\sum\limits_{i=1}^I \left(\alpha_i^{(t)}\right)^2\right)$$

\item[$\bullet$] Générer les \textbf{variables latentes} (ou prédicteurs non mesurés) $W_{il}^{(t)}$ pour $i=1,\ldots,I$ et $l=1,\ldots,q$ selon un algorithme de Metropolis adaptatif  simulant $W_{il}^\star \sim \mathcal{N}(W_{il}^{(t-1)}, \sigma_{W_{il}}^2)$ puis calculant le taux d'acceptation de la manière suivante :

$$\gamma = min\left(1,\ \dfrac{\uppi\left(W_{il}^\star\right)\prod\limits_{1\leq j\leq J}f\left(W_{il}^\star, \alpha_i^{(t)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)},X_i,y_{ij},n_i\right)} {\uppi\left(W_{il}^{(t-1)}\right)\prod\limits_{1\leq j\leq J}f\left(W_{il}^{(t-1)}, \alpha_i^{(t)},\beta_{j0}^{(t-1)},\beta_j^{(t-1)}, \lambda_j^{(t-1)}, X_i,y_{ij},n_i\right)}\right).$$

\item[$\bullet$] Générer les \textbf{effets espèces fixes} $\beta_{jk}^{(t)}$ pour $j=1,\ldots,J$ et $k=0,\ldots,p$ selon un algorithme de Metropolis adaptatif  simulant $\beta_{jk}^\star \sim \mathcal{N}(\beta_{jk}^{(t-1)}, \sigma_{\beta_{jk}}^2)$ puis calculant le taux d'acceptation de la manière suivante :

$$\gamma = min\left(1,\dfrac{\uppi\left(\beta_{jk}^\star\right)\prod\limits_{1\leq i\leq I}f\left(\beta_{j0}^{(t)},\small{\ldots},\beta_{jk-1}^{(t)},\beta_{jk}^\star,\beta_{jk+1}^{(t-1)},\small{\ldots}, \beta_{jp}^{(t-1)},\lambda_j^{(t-1)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)} {\uppi\left(\beta_{jk}^{(t-1)}\right)\prod\limits_{1\leq i\leq I}f\left(\beta_{j0}^{(t)},\small{\ldots},\beta_{jk-1}^{(t)},\beta_{jk}^{(t-1)},\beta_{jk+1}^{(t-1)},\small{\ldots}, \beta_{jp}^{(t-1)},\lambda_j^{(t-1)}, \alpha_1^{(t)},W_1^{(t)}, \small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)}\right).$$
  
\item[$\bullet$] Générer les \textbf{effets espèces fixes liés aux variables latentes} $\lambda_{jl}^{(t)}$ pour $j=1,\ldots,J$ et $l=1,\ldots,q$ selon un algorithme de Metropolis adaptatif pour $l \geq j$, simulant $\lambda_{jl}^\star \sim \mathcal{N}(\lambda_{jl}^{(t-1)},\sigma_{\lambda_{jl}}^2)$ puis calculant le taux d'acceptation de la manière suivante : 
$$\gamma = min\left(1,\dfrac{\uppi\left(\lambda_{jl}^\star\right)\prod\limits_{1\leq i\leq I}f\left(\lambda_{j1}^{(t)},\small{\ldots},\lambda_{jl-1}^{(t)},\lambda_{jl}^\star,\lambda_{jl+1}^{(t-1)},\small{\ldots}, \lambda_{jq}^{(t-1)},\beta_{j0}^{(t)},\beta_j^{(t)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)} {\uppi\left(\lambda_{jl}^{(t-1)}\right)\prod\limits_{1\leq i\leq I}f\left(\lambda_{j1}^{(t)},\small{\ldots},\lambda_{jl-1}^{(t)},\lambda_{jl}^{(t-1)},\lambda_{jl+1}^{(t-1)},\small{\ldots}, \lambda_{jq}^{(t-1)},\beta_{j0}^{(t)},\beta_j^{(t)}, \alpha_1^{(t)},W_1^{(t)},\small{\ldots},\alpha_I^{(t)},  W_I^{(t)},X_i,y_{ij},n_i\right)}\right).$$
Dans le cas $l>j$, on pose $\lambda_{jl}^{(t)} = 0$. 
\end{itemize}
\end{itemize}

\newpage 
## Evaluation de la fiabilité de ces méthodes sur des données simulées 

### Simulation des données 
On simule pour chacun des sites $i$ deux variables bioclimatiques selon une loi normale centrée réduite et on note $X_i=(1,X_{i1},X_{i2})$ pour $i=1,\ldots,500$. 
On considérera deux variables latentes.  
On fixe les paramètres suivants afin de simuler des données de présence absence pour les $100$ espèces et $500$ sites considérés selon les deux modèles définis précédemment.  
Les effets espèces fixes générés selon des lois uniformes : 
$$\begin{aligned}
&\beta_{jk} \sim \mathcal{U}(-2,2) \text{ pour } j=1,\ldots,100 \text{ et } k=0,1,2. \\
&\lambda_{jl} \begin{cases} 
\sim  \mathcal{U}(-2,2) & \text{si } l<j, \\
\sim  \mathcal{U}(0,2) & \text{si } l=j, \\
=  0 & \text{si } l>j, 
\end{cases}\\
&\text{ pour } j=1,\ldots,100 \text{ et } l=1,2.
\end{aligned}$$
Les variables latentes $W_{il} \sim \mathcal{N}(0,1) \text{ pour } i=1,\ldots,500 \text{ et } l=1,2$.  

Les effets sites aléatoires générés selon $\alpha_i \sim \mathcal{N}(0,V_{alpha})$ avec $V_{alpha}$ fixé à $0.5$.

Puis on simule les données de présence absence $Y=(y_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ de la manière apropriée pour chacun des modèles envisagés en fonction des paramètres établis : 

\begin{minipage}[l]{0.6\textwidth}
\textbf{Modèle probit :}   

Pour $i=1,\ldots,500$ et $j=1,\ldots,100$ :   

Générer $\epsilon_{ij} \sim \mathcal{N}(0,1) \ iid$.  

Calculer $Z_{ij}= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j + \epsilon_{ij}$ 

Simuler $y_{ij}=
\begin{cases}
1 & \text{ si } Z_{ij} > 0 \\
0 &  \text{sinon.}
\end{cases}$
\end{minipage}
\begin{minipage}[r]{0.6\textwidth}
\textbf{Modèle logit :}   

Pour $i=1,\ldots,500$ et $j=1,\ldots,100$ :   

Calculer $\mathrm{logit}(\theta_{ij})= \alpha_i + \beta_{j0} + X_i\beta_j + W_i\lambda_j$.  

Calculer $\theta_{ij}= \dfrac{1}{1+\exp\left(-\mathrm{logit}(\theta_{ij})\right)}$.  

Simuler $y_{ij} \sim \mathcal{B}ernoulli(\theta_{ij})$.
\end{minipage}

### Représentation des paramètres estimés 

Les paramètres à estimer sont au nombre de $(p+1)J+qJ-\sum\limits_{j=1}^{q-1}(q-j)+qI+I+1=3\times100+2\times100-1+2\times500+500+1=2 000$, pour chacun d'entre eux les fonctions implémentées retournent un échantillon de $N_{samp}$ valeurs dont on fait la moyenne pour obtenir un estimateur du paramètre.  
On note $\widehat{\beta_{jk}} = \sum\limits_{n=1}^{N_{samp}}\frac{\beta_{jk}^{(n)}}{N_{samp}}$ l'estimateur de $\beta_{jk}$ et on utilise les mêmes notations pour les autres estimateurs.  

On effectue $40 000$ itérations au total dont $35 000$ de burn-in puis $5 000$ durant lesquelles les fonctions implémentées enregistrent les paramètres estimés à partir des données simulées précédemment, toutes les $5$ itérations et renvoient un échantillon de $N_{samp}=1 000$ valeurs pour chacun des paramètres du modèle considéré.   

\textbf{Modèle probit :}

\begin{figure}[H]
 \caption[Représentation des $(\alpha_i)_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\alpha_i)_{i=1,\ldots,I}$ estimés en fonction de ceux simulés pour le modèle probit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/probit_site_effect.png}
\end{figure}

\begin{figure}[H]
 \caption[Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle probit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/probit_W.png}
\end{figure}

\begin{figure}[H]
 \caption[Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/probit_sp_effect.png}
\end{figure} 

\begin{figure}[H]
 \caption[Représentation des $(\mathrm{probit}(\theta_{ij}),Z_{ij},\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\mathrm{probit}(\theta_{ij}))_{i=1,\ldots,500}^{j=1,\ldots,100}$, $(Z_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ et $(\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/probit_proba.png}
\end{figure} 

\textbf{Modèle logit :}
\begin{figure}[H]
 \caption[Représentation des $(\alpha_i)_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(\alpha_i)_{i=1,\ldots,I}$ estimés en fonction de ceux simulés pour le modèle logit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/logit_site_effect.png}
\end{figure}

\begin{figure}[H]
 \caption[Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(W_{il})^{l=1,2}_{i=1,\ldots,500}$ estimés en fonction de ceux simulés pour le modèle logit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/logit_W.png}
\end{figure}

\begin{figure}[H]
 \caption[Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle logit]{Représentation des $(\beta_{jk})^{k=1,2,3}_{j=1,\ldots,100}$ et $(\lambda_{jl})^{l=1,2}_{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle logit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.4\textwidth]{Illustrations/logit_sp_effect.png}
\end{figure} 

\begin{figure}[H]
 \caption[Représentation des $(\mathrm{logit}(\theta_{ij}),\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$  estimés en fonction de ceux simulés pour le modèle probit]{Représentation des $(\mathrm{logit}(\theta_{ij}))_{i=1,\ldots,500}^{j=1,\ldots,100}$ et $(\theta_{ij})_{i=1,\ldots,500}^{j=1,\ldots,100}$ estimés en fonction de ceux simulés pour le modèle probit}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.9\textwidth,height=0.35\textwidth]{Illustrations/logit_proba.png}
\end{figure} 

### Evaluation du temps de calul et de la pertinence des résultats  

\begin{table}[H]\caption[Temps de calcul nécessaires à l'ajustement des modèles logit et probit ainsi que les NRMSE (Normalized Root Mean Square Error) et les pourcentages de déviance expliquée obtenus]{Temps de calcul nécessaires à l'ajustement des modèles logit et probit ainsi que le pourcentage de déviance expliquée et la racine de la moyenne des carrés des erreurs normalisée (NRMSE) obtenus.pour chaque modèle de la manière suivante avec une fonction de lien $g$ probit ou logit :\\
$NRMSE_g=\frac{RMSE_g}{\overline{g(\theta)}}$ avec $\overline{g(\theta)}=\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\frac{g(\theta_{ij})}{IJ}$ et $RMSE=\sqrt{\frac{1}{IJ}\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\left(g(\theta_{ij})-\widehat{g(\theta_{ij})}\right)^2}$.\\ 
Le pourcentage de déviance expliquée est défini par $1-\dfrac{D}{D_0}$ avec $D=-2(l(\widehat{\theta})-l_s)$ la déviance du modèle considéré, où $l_s$ est la log-vraisemblance du modèle saturé comportant autant de paramètres qu'il y a d'observations et dont l'ajustement est supposé parfait par conséquent dans le cas de données binaires, les probabilités ajustées prenant les valeurs $0$ ou $1$ en fonction de celles de $Y$, on a $l_s=0$ car la vraisemblance des données observées sous le modèle saturé est de $1$.\\
De plus la déviance nulle est définie par $D_0=-2(l(\widehat{\theta}_0)-l_s)$ avec $l(\widehat{\theta}_0)$ la log-vraisemblance du modèle nul défini par $g(\theta_{ij})=\mu$, pour lequel le seul paramètre est l'intercept $\mu$.\\
On ajuste le modèle nul avec la fonction jSDM\_binomial() du package jSDM pour le modèle logit et avec Rcpp\_hSDM\_binomial\_probit() pour le modèle probit.\\
Les log-vraisemblance des différents modèles sont calculées avec les paramètres estimés à chaque itération $l(\widehat{\theta})=\sum\limits_{\substack{1\leq i\leq I \\   1 \leq j\leq I}}\log(\mathrm{L}(\widehat{\theta_{ij}}))$ et les valeurs utilisées pour le calcul du pourcentage de déviance expliquée correspondent à la moyenne des $N_{samp}$ valeurs retournées par chacune des fonctions implémentées.}
```{r results-probit-logit, echo=F, include=T}
load("data/probit_logit.RData")
library(dplyr)
T_probit<- as.numeric(T_probit,units="mins")
T_logit <- as.numeric(T_logit,units="mins")
results <- data.frame("Temps"=c(T_probit,T_logit), NRMSE=c(NRMSE_probit,NRMSE_logit), D=c(exp_dev_probit,exp_dev_logit)*100)
colnames(results)<- c("Temps de calcul (mins)","NRMSE","Déviance expliquée (%)")
rownames(results)<- c("Modèle probit","Modèle logit")
knitr::kable(results, row.names=T, digits=1,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table} 

Afin d'ajuster un modèle joint de distribution des espèces à partir des données collectées à Madagascar, on utilisera donc la fonction implémentée pour le modèle probit qui présente un pourcentage de déviance expliquée supérieur, un RMSE inférieur ainsi qu'un temps de calcul bien inférieur à ceux associés au modèle logit, indiquant que les paramètres estimés sont plus en acoord avec les données et proches des valeurs attendues pour le modèle logit.

# Comparaison des packages boral et jSDM 

## Performances sur des données simulées 

On ajuste le modèle joint de distribution des espèces défini précèdemment à partir des données simulées selon le modèle probit à l'aide du package jSDM d'une part et boral d'autre part, puis on compare les résultats obtenus et les temps de calculs nécessaires.

## Comparaison des résultats sur des jeux de données réels 
### Jeux de données utilisés 
### Comparaison des résultats 

\newpage
# Application aux données collectées à Madagascar

## Description des données  

On dispose d'inventaires forestiers réalisés sur $753$ sites de l'île de Madagascar et répertoriant la présence ou l'absence de $555$ espèces végétales sur chacun de ces sites. 
 
Parmi les données climatiques et environnementales concernant Madagascar à l'heure actuelle (interpolations de données observées représentatives des années 1950-2000), disponibles sur le site \url{https://madaclim.cirad.fr}, on choisit d'utiliser les variables suivantes : 

\begin{table}[H]
\caption[Variables bioclimatiques considérées]{Variables bioclimatiques considérées affichées pour quelques sites : \\
Les températures (temp) et précipitations (prec) moyennes annuelles qui sont exprimées respectivement en $^\circ C\times 10$ et millimètres.\\
La saisonnalité des températures (sais\_temp) correspond à l'écart type des températures mensuelles multiplié par $100$ ainsi que la saisonnalité des précipitations (sais\_prec) sous la forme d'un coefficient de variation.\\
Le déficit hydrique climatique (cwd) annuel est calculé en fonction des précipitations et des évapotranspirations potentielles mensuelles (pet) qui sont définies comme la quantité d'évaporation qui se produirait en un mois si une source d'eau suffisante était disponible : \\$\mathrm{cwd}= \sum_{m=1}^{12}\min(0, \ \mathrm{prec}_m-\ \mathrm{pet}_m)$ , il est exprimé en millimètres.  \\
Les trois dernières colonnes correspondent aux coordonnées du site considéré en 
latitude (lat) et longitude (long) ainsi qu'à son identifiant (site).}

```{r site-data-clim, echo=F,include=F}
library(raster)
library(rgdal)
library(readr)
library(dplyr)
s <- stack("data/current.tif")
names(s) <- c(paste("tmin",1:12,sep=""),paste("tmax",1:12,sep=""),
              paste("prec",1:12,sep=""),paste("bio",1:19,sep=""),
              paste("pet",1:12,sep=""),"pet","cwd","ndm")
# get intersting covariables 
clim_var <- dropLayer(s, c(1:36,38,39,41:47,49,50,52:68,70))
names(clim_var) <- c("temp","prec","sais_temp","sais_prec","cwd")

# foresr inventory
trees <- read_csv("data/forest_inventory_Madagascar.csv")
# spatial points of each plot
longlat <- SpatialPoints(unique(cbind(trees$long,trees$lat)))
proj4string(longlat) <- CRS("+proj=longlat +ellps=clrk66")

# latlong to UTM38S projection 
xy <- spTransform(longlat, CRS("+init=epsg:32738"))

# extract climatic data on each plot
clim <-  extract(clim_var,xy)
clim2 <- clim^2
colnames(clim2)<-paste(colnames(clim),rep("2",ncol(clim)),sep="")
pos = unique(trees[,c("long","lat","plot")])
colnames(pos) <- c("long","lat","site")
data_clim <- cbind(clim,pos)
# order plot
ord_data_clim <- data_clim[sort(data_clim$site, index.return=TRUE)$ix,]

# Add squared data
data_clim2 <- cbind(clim,clim2,pos)
nparam <- ncol(data_clim2) -3

library(tidyverse)
# order plot
ord_data_clim2 <- data_clim2[sort(data_clim2$site, index.return=TRUE)$ix,]

# reduced centered data
scaled_data_clim2 <- as_tibble(cbind(scale(ord_data_clim2[1:nparam]),ord_data_clim2[(nparam+1):ncol(ord_data_clim2)]))

```

```{r head-site-data-clim, echo=F}
knitr::kable(head(ord_data_clim), row.names=F, digits=3,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","striped"), full_width=FALSE)
```
\end{table}

On considère également les carrés de ces variables climatiques afin d'effectuer un régression quadratique, plus adaptée pour ajuster un modèle de niche qu'une régression linéaire. On centre et on réduit ces variables afin de former une matrice de design $X$ telle que 
$X_i=(1,\mathrm{temp}_i, \mathrm{prec}_i,\mathrm{sais\_temp}_i, \mathrm{sais\_prec}_i,  \mathrm{cwd}_i,\mathrm{temp}_i^2, \mathrm{prec}_i^2,\mathrm{sais\_temp}_i^2, \mathrm{sais\_prec}_i^2, \mathrm{cwd}_i^2)$ pour $i=1,\ldots,753$.  

Les coordonnées des sites seront utilisées par la suite dans le cadre de l'interpolation spatiale des résultats et représenter spatialement les résultats. 

\newpage
## Estimation des paramètres et représentation des résultats 

### Représentation des réultats pour évaluer la convergence de l'algorithme 

On ajuste un modèle joint de distribution des espèces de fonction de lien probit en considérant deux variables latentes à l'aide de la fonction *jSDM\_probit\_block()* du package jSDM à partir des données décrites précédemment, en effectuant $100 000$ itérations dont $90 000$ de burn-in et on retient $N_{samp}=1 000$ valeurs pour chaque paramètre du modèle que l'on va représenter en fonction du nombre d'itérations effectuées afin d'évaluer la convergence de l'algorithme de Gibbs.  

De plus on affiche une estimation de la densité des échantillons obtenus qui devrait correspondre aux distributions *a posteriori* définies et donc être de forme gaussienne. On met en évidence les moyennes des $N_{samp}$-échantillons en bleu, que l'on utilisera comme estimateur pour les paramètres. 

\begin{table}[H]\caption[Temps de calcul nécessaire à l'ajustement du modèle sur les données de Madagascar et nombre de paramètres à estimer]{Temps de calcul nécessaire à l'ajustement du modèle sur les données de Madagascar et nombre de paramètres à estimer}
```{r results-mada, echo=F, include=T}
library(dplyr)
load("data/mada_mod.RData")
nsp<-ncol(mod_all$model_spec$presences)
nplot<-nrow(mod_all$model_spec$presences)
p <- ncol(mod_all$model_spec$site_data)
T_all <- as.numeric(T_all,units="hours")
results <- data.frame(n_obs=nsp*nplot,n_param=(p+1)*nsp+2*nsp-1+2*nplot+nplot+1,ngibbs=as.integer(100000),"Temps"= T_all)
colnames(results)<- c("Nombre d'observations","Paramètres à estimer","Itérations effectuées","Temps de calcul (heures)")
knitr::kable(results, row.names=F, digits=0,booktabs=TRUE,align = 'c') %>%
		kableExtra::kable_styling(latex_options=c("HOLD_position","basic"), full_width=FALSE)
```
\end{table} 

\begin{figure}[H]
 \caption[Traces et densités de la déviance du modèle]{Traces et densités de la déviance du modèle}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.25\textheight]{Illustrations/mada_deviance.jpeg}
\end{figure}

\begin{figure}[H]
 \caption[Traces et densités des effets espèces fixes $(\beta_{jk})_{j=1}^{k=0,\ldots,10}$ estimés pour la deuxième espèce]{Traces et densités des effets espèces fixes $(\beta_{jk})_{j=2}^{k=0,\ldots,10}$ estimés pour la deuxième espèce}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.35\textheight]{Illustrations/mada_beta1_sp2.jpeg}
\includegraphics[width=0.8\textwidth,height=0.35\textheight]{Illustrations/mada_beta2_sp2.jpeg}
\includegraphics[width=0.8\textwidth,height=0.35\textheight]{Illustrations/mada_beta3_sp2.jpeg}
\end{figure}

\begin{figure}[H]
 \caption[Traces et densités des effets espèces fixes $(\lambda_{jq})_{j=1,2}^{q=1,2}$ estimés pour les deux premières espèces]{Traces et densités des effets espèces fixes $(\lambda_{jq})_{j=1,2}^{q=1,2}$ estimés pour les deux premières espèces}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=10cm,height=10cm]{Illustrations/mada_lambda_sp1.jpeg}\\
\includegraphics[width=10cm,height=10cm]{Illustrations/mada_lambda_sp2.jpeg}
\end{figure}

\begin{figure}[H]
 \caption[Traces et densités des variables latentes $W_1$ et $W_2$ estimées pour un site]{Trace et densité estimées des variables latentes $W_1$ et $W_2$ estimées pour un site}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.3\textheight]{Illustrations/mada_W.jpeg}
\end{figure} 

\begin{figure}[H]\caption[Trace et densité d'un effet site et de la variance associée aux effets sites estimés]{Trace et densité d'un effet site et de la variance associée aux effets sites estimés}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.25\textheight]{Illustrations/mada_rand_site.jpeg}\\
\includegraphics[width=0.8\textwidth,height=0.25\textheight]{Illustrations/mada_Valpha.jpeg}
\end{figure}

### Représentations spatiales des paramètres associés aux sites et des probabilités de présence estimées

\begin{figure}[H]
 \caption[Représentation spatiale des variables latentes $W_1$ et $W_2$ estimées pour chaque site]{Représentation spatiale des variables latentes $W_1$ et $W_2$ estimées pour chaque site}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{Illustrations/mada_W1.png}\includegraphics[width=0.5\textwidth,height=0.5\textwidth]{Illustrations/mada_W2.png}
\end{figure}

\begin{figure}[H]\caption[Représentation spatiale des effets sites $(\alpha_i)_{i=1,\ldots,753}$ estimés]{Représentation spatiale des effets sites estimés}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.5\textwidth,height=0.5\textheight]{Illustrations/mada_site_effect.png}
\end{figure} 

\begin{minipage}[l]{0.5\textwidth}
\begin{figure}[H]\caption[Représentation spatiale des probabilités de présence estimées pour l'espèce Ocotea laevis]{Représentation spatiale des probabilités de présence estimées pour l'espèce Ocotea laevis}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_proba_sp1.png}
\end{figure} 
\end{minipage}
\begin{minipage}[r]{0.5\textwidth}
\begin{figure}[H]\caption[Représentation spatiale des occurences observées de l'espèce Ocotea laevis]{Représentation spatiale des occurences observées de l'espèce Ocotea laevis}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_presence_sp1_obs.png}
\end{figure} 
\end{minipage}

### Estimation de la richesse spécifique propre à chaque site et comparaison à celle observée

\begin{minipage}[l]{0.5\textwidth}
\begin{figure}[H] \caption[Représentation spatiale de la richesse spécifique estimée pour chaque site]{Représentation spatiale de la richesse spécifique estimée pour chaque site par $\widehat{R_i}=\sum\limits_ {j=1}^{555} \widehat{\theta_{ij}}$}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness.png}
\end{figure} 
\end{minipage}
\begin{minipage}[r]{0.5\textwidth}
\begin{figure}[H] \caption[Représentation spatiale de la richesse spécifique observée pour chaque site]{Représentation spatiale de la richesse spécifique observée pour chaque site calculée par $R_i=\sum\limits_ {j=1}^{555} y_{ij}$}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=1.0\textwidth,height=0.5\textheight]{Illustrations/mada_species_richness_obs.png}
\end{figure} 
\end{minipage}

\begin{figure}[H]\caption[Représentation richesse spécifique estimée en fonction de celle observée]{Représentation richesse spécifique estimée en fonction de celle observée}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.4\textwidth,height=0.4\textheight]{Illustrations/mada_species_richness_obs_fit.png}
\end{figure} 

## Comparaison des effets sites obtenus avec différentes méthodes d'interpolation spatiale

définition interpolation et expliquer méthodes

### Thin plate spline

### Ordinary kriging 

### Inverse distance weighted 

### Comparaison des méthodes par validation croisée sur les effets sites estimés

expliquer validation croisée et calcul RMSE

\begin{figure}[H]
 \caption[Comparaison des cartes obtenues pour l'effet site par différentes méthodes d'interpolation]{Comparaison des cartes obtenues pour l'effet site par une interpolation avec la méthode du krigeage ordinaire (OK), de l'inverse de la distance pondéré (IDW) et de thin plate spline (TPS). \\
La carte intitulée ensemble représente la moyenne des résulats obtenus avec les différentes méthodes d'interpolation pondérés par le RMSE de la méthode considérée divisée par la somme des RMSE, qui sont calculés durant la validaton croisée et correspondent à l'écart entre les effets sites interpolés et ceux estimés pour les sites sur lesquels on a collecté des données.}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=0.8\textwidth,height=0.8\textwidth]{Illustrations/comparaison_site_effect.png}
\end{figure}

## Résultats de l'interpolation spatiale par krigeage ordinaire
\begin{figure}[H]
 \caption[Interpolation spatiale des effets sites par krigeage ordinaire]{Interpolation spatiale des effets sites par krigeage ordinaire}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=25cm,height=7cm]{Illustrations/mada_site_effect_OK.png}
\end{figure}
\begin{figure}[H]
 \caption[Interpolation spatiale des variables latentes par krigeage ordinaire]{Interpolation spatiale des variables latentes par krigeage ordinaire}
  \label{fig:condSimApp}
  \centering
\includegraphics[width=25cm,height=7cm]{Illustrations/mada_W1_OK.png}\\
\includegraphics[width=25cm,height=7cm]{Illustrations/mada_W2_OK.png}
\end{figure} 

## Analyse des résultats et mise en évidence de lieux refuges de la biodiversité
résultats species richness theta et probit theta

## Prédictions avec auto-corrélation spatiale
Expliqer méthode CAR + 2D spline qui sont implémentées mais pas abouties les résultats ne sont pas satisfaisants pour l'instant. 

\newpage
\pagestyle{simple}

\section*{Conclusion}
\addcontentsline{toc}{section}{Conclusion}
données GIECC pour évolution biodiversité avec changement climatique, intégrer traits spécifiques dans le modèle, enrichir le package,  
\section*{Bibliographie}
\addcontentsline{toc}{section}{Bibliographie}

<div id="refs"></div>

\newpage
\section*{Annexes}
\addcontentsline{toc}{section}{Annexe}

\subsection*{Fonction utilisée pour le modèle probit}

```{r Rcpp_jSDM_probit_block, engine="Rcpp", eval=F}
#include <RcppArmadillo.h>
#include <gsl/gsl_rng.h>
#include <gsl/gsl_randist.h>
#include <gsl/gsl_cdf.h>
#include <cmath>
#include "Rcpp_jSDM_useful.h"

// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::depends(RcppGSL)]]

using namespace arma;
using namespace std;

/* ************************************************************ */
/* Gibbs sampler function */

// [[Rcpp::export]]
Rcpp::List Rcpp_jSDM_probit_block(const int ngibbs, int nthin, int nburn, 
                                  arma::umat Y, 
                                  arma::umat T, 
                                  arma::mat X,
                                  arma::mat param_start,
                                  arma::mat Vparam,
                                  arma::vec muparam,
                                  arma::mat VW,
                                  arma::mat W_start,
                                  arma::vec alpha_start,
                                  double Valpha_start,
                                  double shape,
                                  double rate,
                                  const int seed,
                                  const int verbose) {
  
  ///////////////////////////////////////
 // Defining and initializing objects//
  
  // Initialize random number generator 
  gsl_rng *s = gsl_rng_alloc(gsl_rng_mt19937);
  gsl_rng_set(s, seed);
  
  // Redefining constants 
  const int NGIBBS = ngibbs;
  const int NTHIN = nthin;
  const int NBURN = nburn;
  const int NSAMP = (NGIBBS-NBURN)/NTHIN;
  const int NSITE = Y.n_rows;
  const int NP = X.n_cols;
  const int NSP = Y.n_cols;
  const int NL = W_start.n_cols; 
  
  /////////////////////////////////////////////
  // Declaring new objects to store results //
  /* Parameters */
  arma::Cube<double> param; param.zeros(NSAMP, NSP, NP+NL);
  arma::Cube<double> W; W.zeros(NSAMP, NSITE, NL);
  arma::mat alpha; alpha.zeros(NSAMP, NSITE);
  arma::vec Valpha; Valpha.zeros(NSAMP);
  /* Latent variable */
  arma::mat probit_theta_pred; probit_theta_pred.zeros(NSITE, NSP);
  arma::mat Z_latent; Z_latent.zeros(NSITE, NSP);
  /* Deviance */
  arma::vec Deviance; Deviance.zeros(NSAMP);
  
   /////////////////////////////////////
  // Initializing running parameters //
  
  //  mat of species effects parameters and coefficients for latent variables (nl+np,nsp)
  arma::mat param_run = param_start;
  // alpha vec of sites effects (nsite)
  arma::vec alpha_run = alpha_start;
  double Valpha_run = Valpha_start;
  // w latent variables (nsite*nl)
  arma::mat W_run = W_start;
  // Z latent (nsite*nsp)
  arma::mat Z_run; Z_run.zeros(NSITE,NSP);
  // probit_theta_ij = X_i*beta_j + W_i*lambda_j + alpha_i
  arma::mat probit_theta_run; probit_theta_run.zeros(NSITE,NSP);
  // data 
  arma::mat data = arma::join_rows(X,W_run);
  
  ////////////
  // Message//
  Rprintf("\nRunning the Gibbs sampler. It may be long, please keep cool :)\n\n");
  R_FlushConsole();
  
  ///////////////////////////////////////////////////////////////////////////////////////
  //%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  // Gibbs sampler 
  
  for (int g=0; g < NGIBBS; g++) {
    
    ////////////////////////
    // latent variable Z // 
    
    for (int j=0; j<NSP; j++) {
      for (int i=0; i<NSITE; i++) {
        // Actualization
        if (Y(i,j) == 0) {
          Z_run(i,j) = rtnorm(s, R_NegInf, 0, probit_theta_run(i,j), 1);
        } else {
          Z_run(i,j) = rtnorm(s, 0, R_PosInf, probit_theta_run(i,j), 1);
        }
      } // loop on sites
    }// loop on species
  
    //////////////////////////////////
    // mat param: Gibbs algorithm //
    
    // Loop on species
    for (int j=0; j<NSP; j++) {
      // small_v
      arma::vec small_v = inv(Vparam)*muparam + data.t()*(Z_run.col(j) - alpha_run);
      // big_V
      arma::mat big_V = inv(inv(Vparam)+data.t()*data);
      // Draw in the posterior distribution
      arma::vec param_prop = arma_mvgauss(s, big_V*small_v, chol_decomp(big_V));
      
      // constraints on lambda
      for (int l=0; l<NL; l++) {
        if (l > j) {
          param_prop(NP+l) = 0;
        }
        if ((l==j) & (param_prop(NP+l) < 0)) {
          param_prop(NP+l) = param_run(NP+l,j);
        }
      }
      param_run.col(j) = param_prop;
    }// loop on species
    
    
    /////////////////////////////////////////////
    // mat latent variable W: Gibbs algorithm //
    
    // Loop on sites
    for (int i=0; i<NSITE; i++) {
      arma::mat beta_run = param_run.submat(0,0,NP-1,NSP-1);
      arma::mat lambda_run = param_run.submat(NP,0,NP+NL-1,NSP-1);
      // big_V
      arma::mat big_V = inv(inv(VW)+lambda_run*lambda_run.t());
      
      // small_v
      arma::vec small_v =lambda_run*(Z_run.row(i)-X.row(i)*beta_run-alpha_run(i)).t();
      
      // Draw in the posterior distribution
      arma::vec W_i = arma_mvgauss(s, big_V*small_v, chol_decomp(big_V));
      W_run.row(i) = W_i.t();
    }
    
    data = arma::join_rows(X, W_run);
    
    //////////////////////////////////
    // vec alpha : Gibbs algorithm //
    
    // Loop on sites 
    double sum = 0.0;
    for (int i=0; i<NSITE; i++) {
      // small_v
      double small_v = arma::sum(Z_run.row(i)-data.row(i)*param_run);
      // big_V
      double big_V = 1/(1/Valpha_run + NSP);
      
      // Draw in the posterior distribution
      alpha_run(i) = big_V*small_v + gsl_ran_gaussian_ziggurat(s, std::sqrt(big_V));
      sum += alpha_run(i)*alpha_run(i);
    }
    
    ////////////////////////////////////////////////
    // Valpha
    double shape_posterior = shape + 0.5*NSITE;
    double rate_posterior = rate + 0.5*sum;
    
    Valpha_run = rate_posterior/gsl_ran_gamma_mt(s, shape_posterior, 1.0);
    
     //////////////
    // Deviance //
    
    // logLikelihood
    double logL = 0.0;
    for ( int i = 0; i < NSITE; i++ ) {
      for ( int j = 0; j < NSP; j++ ) {
        // probit(theta_ij) = X_i*beta_j + W_i*lambda_j + alpha_i 
        probit_theta_run(i,j) = arma::as_scalar(data.row(i)*param_run.col(j) + alpha_run(i));
        // link function probit is the inverse of N(0,1) repartition function 
        double theta = gsl_cdf_ugaussian_P(probit_theta_run(i,j));
        /* log Likelihood */
        logL += R::dbinom(Y(i,j), T(i,j), theta, 1);
      } // loop on species
    } // loop on sites
    
    // Deviance
    double Deviance_run = -2 * logL;
    
    //////////////////////////////////////////////////
    // Output
    if (((g+1)>NBURN) && (((g+1)%(NTHIN))==0)) {
      int isamp=((g+1)-NBURN)/(NTHIN);
      for ( int j=0; j<NSP; j++ ) {
        param.tube(isamp-1,j) = param_run.col(j);
        for ( int i=0; i<NSITE; i++ ) {
          W.tube(isamp-1,i) = W_run.row(i);
          Z_latent(i,j) += Z_run(i,j) / NSAMP; // We compute the mean of NSAMP values
          probit_theta_pred(i,j) += probit_theta_run(i,j)/NSAMP;        
        }
      }
      alpha.row(isamp-1) = alpha_run.t();
      Valpha(isamp-1) = Valpha_run;
      Deviance(isamp-1) = Deviance_run;
    }
    
    //////////////////////////////////////////////////
    // Progress bar
    double Perc=100*(g+1)/(NGIBBS);
    if (((g+1)%(NGIBBS/100))==0 && (verbose==1)) {  
      Rprintf("*");
      R_FlushConsole();
      //R_ProcessEvents(); for windows
      if (((g+1)%(NGIBBS/10))==0) {
        Rprintf(":%.1f%% \n",Perc);
        R_FlushConsole();
        //R_ProcessEvents(); for windows
      }
    } 
    
    ///////////////////
  // User interrupt //
    R_CheckUserInterrupt(); // allow user interrupts 	    
    
  } // Gibbs sampler
  
  // Free memory
  gsl_rng_free(s);
  
  // Return results as a Rcpp::List
  Rcpp::List results = Rcpp::List::create(Rcpp::Named("param") = param,
                                          Rcpp::Named("W") = W,
                                          Rcpp::Named("alpha") = alpha,
                                          Rcpp::Named("Valpha") = Valpha,
                                          Rcpp::Named("Deviance") = Deviance,
                                          Rcpp::Named("Z_latent") = Z_latent,
                                          Rcpp::Named("probit_theta_pred") = probit_theta_pred);  
  return results;
  
} // end Rcpp_jSDM_probit_block
```

